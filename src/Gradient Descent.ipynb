{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_networks import Model\n",
    "from neural_networks.preprocessing import one_hot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>123</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>124</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>125</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>126</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>135</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  \\\n",
       "0             1           5.1          3.5           1.4          0.2   \n",
       "1             2           4.9          3.0           1.4          0.2   \n",
       "2             3           4.7          3.2           1.3          0.2   \n",
       "3             4           4.6          3.1           1.5          0.2   \n",
       "4             5           5.0          3.6           1.4          0.2   \n",
       "5             6           5.4          3.9           1.7          0.4   \n",
       "6             7           4.6          3.4           1.4          0.3   \n",
       "7             8           5.0          3.4           1.5          0.2   \n",
       "8             9           4.4          2.9           1.4          0.2   \n",
       "9            10           4.9          3.1           1.5          0.1   \n",
       "10           11           5.4          3.7           1.5          0.2   \n",
       "11           12           4.8          3.4           1.6          0.2   \n",
       "12           13           4.8          3.0           1.4          0.1   \n",
       "13           14           4.3          3.0           1.1          0.1   \n",
       "14           15           5.8          4.0           1.2          0.2   \n",
       "15           16           5.7          4.4           1.5          0.4   \n",
       "16           17           5.4          3.9           1.3          0.4   \n",
       "17           18           5.1          3.5           1.4          0.3   \n",
       "18           19           5.7          3.8           1.7          0.3   \n",
       "19           20           5.1          3.8           1.5          0.3   \n",
       "20           21           5.4          3.4           1.7          0.2   \n",
       "21           22           5.1          3.7           1.5          0.4   \n",
       "22           23           4.6          3.6           1.0          0.2   \n",
       "23           24           5.1          3.3           1.7          0.5   \n",
       "24           25           4.8          3.4           1.9          0.2   \n",
       "25           26           5.0          3.0           1.6          0.2   \n",
       "26           27           5.0          3.4           1.6          0.4   \n",
       "27           28           5.2          3.5           1.5          0.2   \n",
       "28           29           5.2          3.4           1.4          0.2   \n",
       "29           30           4.7          3.2           1.6          0.2   \n",
       "..          ...           ...          ...           ...          ...   \n",
       "120         121           6.9          3.2           5.7          2.3   \n",
       "121         122           5.6          2.8           4.9          2.0   \n",
       "122         123           7.7          2.8           6.7          2.0   \n",
       "123         124           6.3          2.7           4.9          1.8   \n",
       "124         125           6.7          3.3           5.7          2.1   \n",
       "125         126           7.2          3.2           6.0          1.8   \n",
       "126         127           6.2          2.8           4.8          1.8   \n",
       "127         128           6.1          3.0           4.9          1.8   \n",
       "128         129           6.4          2.8           5.6          2.1   \n",
       "129         130           7.2          3.0           5.8          1.6   \n",
       "130         131           7.4          2.8           6.1          1.9   \n",
       "131         132           7.9          3.8           6.4          2.0   \n",
       "132         133           6.4          2.8           5.6          2.2   \n",
       "133         134           6.3          2.8           5.1          1.5   \n",
       "134         135           6.1          2.6           5.6          1.4   \n",
       "135         136           7.7          3.0           6.1          2.3   \n",
       "136         137           6.3          3.4           5.6          2.4   \n",
       "137         138           6.4          3.1           5.5          1.8   \n",
       "138         139           6.0          3.0           4.8          1.8   \n",
       "139         140           6.9          3.1           5.4          2.1   \n",
       "140         141           6.7          3.1           5.6          2.4   \n",
       "141         142           6.9          3.1           5.1          2.3   \n",
       "142         143           5.8          2.7           5.1          1.9   \n",
       "143         144           6.8          3.2           5.9          2.3   \n",
       "144         145           6.7          3.3           5.7          2.5   \n",
       "145         146           6.7          3.0           5.2          2.3   \n",
       "146         147           6.3          2.5           5.0          1.9   \n",
       "147         148           6.5          3.0           5.2          2.0   \n",
       "148         149           6.2          3.4           5.4          2.3   \n",
       "149         150           5.9          3.0           5.1          1.8   \n",
       "\n",
       "       Species  \n",
       "0       setosa  \n",
       "1       setosa  \n",
       "2       setosa  \n",
       "3       setosa  \n",
       "4       setosa  \n",
       "5       setosa  \n",
       "6       setosa  \n",
       "7       setosa  \n",
       "8       setosa  \n",
       "9       setosa  \n",
       "10      setosa  \n",
       "11      setosa  \n",
       "12      setosa  \n",
       "13      setosa  \n",
       "14      setosa  \n",
       "15      setosa  \n",
       "16      setosa  \n",
       "17      setosa  \n",
       "18      setosa  \n",
       "19      setosa  \n",
       "20      setosa  \n",
       "21      setosa  \n",
       "22      setosa  \n",
       "23      setosa  \n",
       "24      setosa  \n",
       "25      setosa  \n",
       "26      setosa  \n",
       "27      setosa  \n",
       "28      setosa  \n",
       "29      setosa  \n",
       "..         ...  \n",
       "120  virginica  \n",
       "121  virginica  \n",
       "122  virginica  \n",
       "123  virginica  \n",
       "124  virginica  \n",
       "125  virginica  \n",
       "126  virginica  \n",
       "127  virginica  \n",
       "128  virginica  \n",
       "129  virginica  \n",
       "130  virginica  \n",
       "131  virginica  \n",
       "132  virginica  \n",
       "133  virginica  \n",
       "134  virginica  \n",
       "135  virginica  \n",
       "136  virginica  \n",
       "137  virginica  \n",
       "138  virginica  \n",
       "139  virginica  \n",
       "140  virginica  \n",
       "141  virginica  \n",
       "142  virginica  \n",
       "143  virginica  \n",
       "144  virginica  \n",
       "145  virginica  \n",
       "146  virginica  \n",
       "147  virginica  \n",
       "148  virginica  \n",
       "149  virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data.values)[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "total = len(data)\n",
    "split_index = int(total * split)\n",
    "\n",
    "X, y = data[:,:-1], data[:,-1]\n",
    "X_train, y_train = X[:split_index,].astype(float), y[:split_index,]\n",
    "X_test, y_test = X[split_index:,].astype(float), y[split_index:,]\n",
    "\n",
    "y_train = one_hot_encoded(y_train)\n",
    "y_test = one_hot_encoded(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense neural network with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "model.add_dense_layer(7, 4, activation='relu')\n",
    "model.add_dense_layer(3, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_parameters(lr=0.01, loss='mse', optimization='gd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches by default in Gradient descent is set to 1\n",
      "Epoch  0\n",
      "Loss:  0.15479426861677112\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  1\n",
      "Loss:  0.1453155963061458\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  2\n",
      "Loss:  0.1456674764205953\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  3\n",
      "Loss:  0.1444249179163829\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  4\n",
      "Loss:  0.14396768362230616\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  5\n",
      "Loss:  0.14321812209150586\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  6\n",
      "Loss:  0.14171129090142728\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  7\n",
      "Loss:  0.1375044328503096\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  8\n",
      "Loss:  0.12440940070123892\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  9\n",
      "Loss:  0.10567464296396788\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  10\n",
      "Loss:  0.10681375664830887\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  11\n",
      "Loss:  0.10458344688605159\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  12\n",
      "Loss:  0.10377123772159476\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  13\n",
      "Loss:  0.10280224083273218\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  14\n",
      "Loss:  0.1019656853555074\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  15\n",
      "Loss:  0.10109463147165858\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  16\n",
      "Loss:  0.10012400373529609\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  17\n",
      "Loss:  0.09909053305041216\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  18\n",
      "Loss:  0.09798836047278046\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  19\n",
      "Loss:  0.09680207864290644\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  20\n",
      "Loss:  0.09552721879465535\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  21\n",
      "Loss:  0.0941594434354457\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  22\n",
      "Loss:  0.09269164924940214\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  23\n",
      "Loss:  0.09111986401407667\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  24\n",
      "Loss:  0.08945060826517716\n",
      "Accuracy:  0.35\n",
      "\n",
      "Epoch  25\n",
      "Loss:  0.08766867830479969\n",
      "Accuracy:  0.35833333333333334\n",
      "\n",
      "Epoch  26\n",
      "Loss:  0.08579235787743197\n",
      "Accuracy:  0.38333333333333336\n",
      "\n",
      "Epoch  27\n",
      "Loss:  0.08381513535374817\n",
      "Accuracy:  0.525\n",
      "\n",
      "Epoch  28\n",
      "Loss:  0.08176903908921986\n",
      "Accuracy:  0.6833333333333333\n",
      "\n",
      "Epoch  29\n",
      "Loss:  0.08037617652909275\n",
      "Accuracy:  0.7\n",
      "\n",
      "Epoch  30\n",
      "Loss:  0.07992938988389019\n",
      "Accuracy:  0.6916666666666667\n",
      "\n",
      "Epoch  31\n",
      "Loss:  0.0800422983408679\n",
      "Accuracy:  0.675\n",
      "\n",
      "Epoch  32\n",
      "Loss:  0.08041581774928797\n",
      "Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  33\n",
      "Loss:  0.08101218308077793\n",
      "Accuracy:  0.6166666666666667\n",
      "\n",
      "Epoch  34\n",
      "Loss:  0.08179469826859666\n",
      "Accuracy:  0.43333333333333335\n",
      "\n",
      "Epoch  35\n",
      "Loss:  0.08228352924261603\n",
      "Accuracy:  0.36666666666666664\n",
      "\n",
      "Epoch  36\n",
      "Loss:  0.08179056300294904\n",
      "Accuracy:  0.6583333333333333\n",
      "\n",
      "Epoch  37\n",
      "Loss:  0.08114915605250554\n",
      "Accuracy:  0.675\n",
      "\n",
      "Epoch  38\n",
      "Loss:  0.08048805213753521\n",
      "Accuracy:  0.6833333333333333\n",
      "\n",
      "Epoch  39\n",
      "Loss:  0.07981927711208875\n",
      "Accuracy:  0.6833333333333333\n",
      "\n",
      "Epoch  40\n",
      "Loss:  0.07915340280621896\n",
      "Accuracy:  0.6916666666666667\n",
      "\n",
      "Epoch  41\n",
      "Loss:  0.07849343733570321\n",
      "Accuracy:  0.6916666666666667\n",
      "\n",
      "Epoch  42\n",
      "Loss:  0.0778383785807175\n",
      "Accuracy:  0.6916666666666667\n",
      "\n",
      "Epoch  43\n",
      "Loss:  0.07717999609442143\n",
      "Accuracy:  0.6916666666666667\n",
      "\n",
      "Epoch  44\n",
      "Loss:  0.07654282691099858\n",
      "Accuracy:  0.6916666666666667\n",
      "\n",
      "Epoch  45\n",
      "Loss:  0.07590663924307713\n",
      "Accuracy:  0.6916666666666667\n",
      "\n",
      "Epoch  46\n",
      "Loss:  0.0752850775026284\n",
      "Accuracy:  0.6916666666666667\n",
      "\n",
      "Epoch  47\n",
      "Loss:  0.07467230756907993\n",
      "Accuracy:  0.7\n",
      "\n",
      "Epoch  48\n",
      "Loss:  0.07406728429978113\n",
      "Accuracy:  0.7\n",
      "\n",
      "Epoch  49\n",
      "Loss:  0.0734695752430517\n",
      "Accuracy:  0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(X_train, y_train, 50, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2]\n",
      "Loss:  0.07586461044659526\n",
      "Accuracy:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition of an extra layer with 4 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "model.add_dense_layer(7, 4, activation='relu')\n",
    "model.add_dense_layer(4, activation='relu')\n",
    "model.add_dense_layer(3, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_parameters(lr=0.01, loss='mse', optimization='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Loss:  0.1184643989256129\n",
      "Accuracy:  0.31666666666666665\n",
      "\n",
      "Epoch  1\n",
      "Loss:  0.11771826718129616\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  2\n",
      "Loss:  0.11743406381241586\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  3\n",
      "Loss:  0.11715489108735053\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  4\n",
      "Loss:  0.11688300308836135\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  5\n",
      "Loss:  0.11664554795030789\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  6\n",
      "Loss:  0.11624251173545944\n",
      "Accuracy:  0.325\n",
      "\n",
      "Epoch  7\n",
      "Loss:  0.11327260579705012\n",
      "Accuracy:  0.4\n",
      "\n",
      "Epoch  8\n",
      "Loss:  0.10952417837500943\n",
      "Accuracy:  0.6333333333333333\n",
      "\n",
      "Epoch  9\n",
      "Loss:  0.10825926943098312\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  10\n",
      "Loss:  0.10731658307893811\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  11\n",
      "Loss:  0.10637510045537112\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  12\n",
      "Loss:  0.10540982230473642\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  13\n",
      "Loss:  0.10442273340067099\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  14\n",
      "Loss:  0.10343124026951686\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  15\n",
      "Loss:  0.10243983081694227\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  16\n",
      "Loss:  0.10143953125977986\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  17\n",
      "Loss:  0.10042951813750871\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  18\n",
      "Loss:  0.09941235705337736\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  19\n",
      "Loss:  0.09839071315117628\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  20\n",
      "Loss:  0.0973673094188277\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  21\n",
      "Loss:  0.09634488283514821\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  22\n",
      "Loss:  0.0953251671009835\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  23\n",
      "Loss:  0.09431266891252851\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  24\n",
      "Loss:  0.09330746505940869\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  25\n",
      "Loss:  0.09231034311744578\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  26\n",
      "Loss:  0.09133358502206015\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  27\n",
      "Loss:  0.09037128787622893\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  28\n",
      "Loss:  0.0894257685137358\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  29\n",
      "Loss:  0.08849443644690472\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  30\n",
      "Loss:  0.08758819024447584\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  31\n",
      "Loss:  0.08670031498510104\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  32\n",
      "Loss:  0.08583627767895771\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  33\n",
      "Loss:  0.08500449834622277\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  34\n",
      "Loss:  0.08418590182630487\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  35\n",
      "Loss:  0.08339153497560603\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  36\n",
      "Loss:  0.08262108045930304\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  37\n",
      "Loss:  0.08187382603394495\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  38\n",
      "Loss:  0.08114988572931843\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  39\n",
      "Loss:  0.0804554382913789\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  40\n",
      "Loss:  0.07977845098049845\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  41\n",
      "Loss:  0.0791235074066683\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  42\n",
      "Loss:  0.0784903167626197\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  43\n",
      "Loss:  0.07788473994626732\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  44\n",
      "Loss:  0.07729392980633047\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  45\n",
      "Loss:  0.07672903042176471\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  46\n",
      "Loss:  0.07617849550933321\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  47\n",
      "Loss:  0.07565222910976226\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  48\n",
      "Loss:  0.07513934995941132\n",
      "Accuracy:  0.65\n",
      "\n",
      "Epoch  49\n",
      "Loss:  0.07464959736353384\n",
      "Accuracy:  0.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(X_train, y_train, 50, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n",
      "Loss:  0.07001404953141808\n",
      "Accuracy:  0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 0, 2, 1, 0, 1, 0, 2, 0, 1, 0, 1, 1, 1, 1, 2, 0, 1, 0, 1, 2, 0, 2, 0, 1, 0, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print([np.argmax(i) for i in y_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
