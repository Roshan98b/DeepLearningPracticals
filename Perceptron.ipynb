{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neural_networks import Model, one_hot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron - 2 inputs, 1 output <br>\n",
    "Sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "model.add_dense_layer(1, 2, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset - OR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[0, 0], [0, 1], [1, 0]])\n",
    "y_train = np.array([0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Hyperparameters: <br>\n",
    "Loss Function: Mean Square Error(mse) <br> \n",
    "Learning rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_parameters(lr=0.1, loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Training Loss:  [0.1717802]\n",
      "Training Accuracy:  0.3333333333333333\n",
      "\n",
      "Epoch  1\n",
      "Training Loss:  [0.16943442]\n",
      "Training Accuracy:  0.3333333333333333\n",
      "\n",
      "Epoch  2\n",
      "Training Loss:  [0.1667087]\n",
      "Training Accuracy:  0.3333333333333333\n",
      "\n",
      "Epoch  3\n",
      "Training Loss:  [0.16380504]\n",
      "Training Accuracy:  0.3333333333333333\n",
      "\n",
      "Epoch  4\n",
      "Training Loss:  [0.16082727]\n",
      "Training Accuracy:  0.3333333333333333\n",
      "\n",
      "Epoch  5\n",
      "Training Loss:  [0.1578301]\n",
      "Training Accuracy:  0.3333333333333333\n",
      "\n",
      "Epoch  6\n",
      "Training Loss:  [0.15484354]\n",
      "Training Accuracy:  0.3333333333333333\n",
      "\n",
      "Epoch  7\n",
      "Training Loss:  [0.15188517]\n",
      "Training Accuracy:  0.3333333333333333\n",
      "\n",
      "Epoch  8\n",
      "Training Loss:  [0.14896615]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  9\n",
      "Training Loss:  [0.14609431]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  10\n",
      "Training Loss:  [0.14327558]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  11\n",
      "Training Loss:  [0.14051477]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  12\n",
      "Training Loss:  [0.13781588]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  13\n",
      "Training Loss:  [0.13518231]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  14\n",
      "Training Loss:  [0.13261691]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  15\n",
      "Training Loss:  [0.13012205]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  16\n",
      "Training Loss:  [0.12769963]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  17\n",
      "Training Loss:  [0.12535109]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  18\n",
      "Training Loss:  [0.12307745]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  19\n",
      "Training Loss:  [0.1208793]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  20\n",
      "Training Loss:  [0.11875685]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  21\n",
      "Training Loss:  [0.11670992]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  22\n",
      "Training Loss:  [0.11473802]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  23\n",
      "Training Loss:  [0.1128403]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  24\n",
      "Training Loss:  [0.11101568]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  25\n",
      "Training Loss:  [0.10926279]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  26\n",
      "Training Loss:  [0.10758005]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  27\n",
      "Training Loss:  [0.10596571]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  28\n",
      "Training Loss:  [0.10441783]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  29\n",
      "Training Loss:  [0.10293437]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  30\n",
      "Training Loss:  [0.10151318]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  31\n",
      "Training Loss:  [0.10015203]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  32\n",
      "Training Loss:  [0.09884864]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  33\n",
      "Training Loss:  [0.09760071]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  34\n",
      "Training Loss:  [0.09640592]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  35\n",
      "Training Loss:  [0.09526196]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  36\n",
      "Training Loss:  [0.09416654]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  37\n",
      "Training Loss:  [0.09311741]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  38\n",
      "Training Loss:  [0.09211236]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  39\n",
      "Training Loss:  [0.09114923]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  40\n",
      "Training Loss:  [0.09022594]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  41\n",
      "Training Loss:  [0.08934046]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  42\n",
      "Training Loss:  [0.08849084]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  43\n",
      "Training Loss:  [0.0876752]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  44\n",
      "Training Loss:  [0.08689174]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  45\n",
      "Training Loss:  [0.08613874]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  46\n",
      "Training Loss:  [0.08541454]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  47\n",
      "Training Loss:  [0.08471759]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  48\n",
      "Training Loss:  [0.0840464]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  49\n",
      "Training Loss:  [0.08339953]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  50\n",
      "Training Loss:  [0.08277566]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  51\n",
      "Training Loss:  [0.0821735]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  52\n",
      "Training Loss:  [0.08159185]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  53\n",
      "Training Loss:  [0.08102958]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  54\n",
      "Training Loss:  [0.08048561]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  55\n",
      "Training Loss:  [0.07995891]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  56\n",
      "Training Loss:  [0.07944854]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  57\n",
      "Training Loss:  [0.0789536]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  58\n",
      "Training Loss:  [0.07847322]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  59\n",
      "Training Loss:  [0.0780066]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  60\n",
      "Training Loss:  [0.07755301]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  61\n",
      "Training Loss:  [0.07711171]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  62\n",
      "Training Loss:  [0.07668205]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  63\n",
      "Training Loss:  [0.07626339]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  64\n",
      "Training Loss:  [0.07585515]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  65\n",
      "Training Loss:  [0.07545677]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  66\n",
      "Training Loss:  [0.07506771]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  67\n",
      "Training Loss:  [0.0746875]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  68\n",
      "Training Loss:  [0.07431567]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  69\n",
      "Training Loss:  [0.07395177]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  70\n",
      "Training Loss:  [0.07359541]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  71\n",
      "Training Loss:  [0.0732462]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  72\n",
      "Training Loss:  [0.07290376]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  73\n",
      "Training Loss:  [0.07256777]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  74\n",
      "Training Loss:  [0.07223789]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  75\n",
      "Training Loss:  [0.07191384]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  76\n",
      "Training Loss:  [0.07159531]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  77\n",
      "Training Loss:  [0.07128205]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  78\n",
      "Training Loss:  [0.07097379]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  79\n",
      "Training Loss:  [0.07067031]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  80\n",
      "Training Loss:  [0.07037137]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  81\n",
      "Training Loss:  [0.07007677]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  82\n",
      "Training Loss:  [0.0697863]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  83\n",
      "Training Loss:  [0.06949979]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  84\n",
      "Training Loss:  [0.06921704]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  85\n",
      "Training Loss:  [0.06893789]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  86\n",
      "Training Loss:  [0.06866218]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  87\n",
      "Training Loss:  [0.06838978]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  88\n",
      "Training Loss:  [0.06812052]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  89\n",
      "Training Loss:  [0.06785428]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  90\n",
      "Training Loss:  [0.06759094]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  91\n",
      "Training Loss:  [0.06733038]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  92\n",
      "Training Loss:  [0.06707247]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  93\n",
      "Training Loss:  [0.06681713]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  94\n",
      "Training Loss:  [0.06656423]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  95\n",
      "Training Loss:  [0.0663137]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  96\n",
      "Training Loss:  [0.06606544]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  97\n",
      "Training Loss:  [0.06581937]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  98\n",
      "Training Loss:  [0.0655754]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  99\n",
      "Training Loss:  [0.06533346]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  100\n",
      "Training Loss:  [0.06509347]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  101\n",
      "Training Loss:  [0.06485537]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  102\n",
      "Training Loss:  [0.0646191]\n",
      "Training Accuracy:  0.6666666666666666\n",
      "\n",
      "Epoch  103\n",
      "Training Loss:  [0.06438458]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  104\n",
      "Training Loss:  [0.06415177]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  105\n",
      "Training Loss:  [0.0639206]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  106\n",
      "Training Loss:  [0.06369102]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  107\n",
      "Training Loss:  [0.06346299]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  108\n",
      "Training Loss:  [0.06323646]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  109\n",
      "Training Loss:  [0.06301137]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  110\n",
      "Training Loss:  [0.0627877]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  111\n",
      "Training Loss:  [0.06256539]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  112\n",
      "Training Loss:  [0.06234441]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  113\n",
      "Training Loss:  [0.06212473]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  114\n",
      "Training Loss:  [0.0619063]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  115\n",
      "Training Loss:  [0.06168909]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  116\n",
      "Training Loss:  [0.06147308]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  117\n",
      "Training Loss:  [0.06125824]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  118\n",
      "Training Loss:  [0.06104452]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  119\n",
      "Training Loss:  [0.06083192]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  120\n",
      "Training Loss:  [0.06062039]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  121\n",
      "Training Loss:  [0.06040992]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  122\n",
      "Training Loss:  [0.06020049]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  123\n",
      "Training Loss:  [0.05999207]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  124\n",
      "Training Loss:  [0.05978464]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  125\n",
      "Training Loss:  [0.05957817]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  126\n",
      "Training Loss:  [0.05937266]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  127\n",
      "Training Loss:  [0.05916808]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  128\n",
      "Training Loss:  [0.05896442]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  129\n",
      "Training Loss:  [0.05876165]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  130\n",
      "Training Loss:  [0.05855977]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  131\n",
      "Training Loss:  [0.05835875]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  132\n",
      "Training Loss:  [0.05815859]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  133\n",
      "Training Loss:  [0.05795926]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  134\n",
      "Training Loss:  [0.05776076]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  135\n",
      "Training Loss:  [0.05756308]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  136\n",
      "Training Loss:  [0.05736619]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  137\n",
      "Training Loss:  [0.0571701]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  138\n",
      "Training Loss:  [0.05697478]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  139\n",
      "Training Loss:  [0.05678024]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  140\n",
      "Training Loss:  [0.05658645]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  141\n",
      "Training Loss:  [0.05639341]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  142\n",
      "Training Loss:  [0.05620111]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  143\n",
      "Training Loss:  [0.05600955]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  144\n",
      "Training Loss:  [0.0558187]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  145\n",
      "Training Loss:  [0.05562858]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  146\n",
      "Training Loss:  [0.05543916]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  147\n",
      "Training Loss:  [0.05525044]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  148\n",
      "Training Loss:  [0.05506242]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  149\n",
      "Training Loss:  [0.05487508]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  150\n",
      "Training Loss:  [0.05468842]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  151\n",
      "Training Loss:  [0.05450244]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  152\n",
      "Training Loss:  [0.05431713]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  153\n",
      "Training Loss:  [0.05413248]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  154\n",
      "Training Loss:  [0.0539485]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  155\n",
      "Training Loss:  [0.05376516]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  156\n",
      "Training Loss:  [0.05358247]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  157\n",
      "Training Loss:  [0.05340043]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  158\n",
      "Training Loss:  [0.05321903]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  159\n",
      "Training Loss:  [0.05303826]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  160\n",
      "Training Loss:  [0.05285813]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  161\n",
      "Training Loss:  [0.05267862]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  162\n",
      "Training Loss:  [0.05249974]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  163\n",
      "Training Loss:  [0.05232148]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  164\n",
      "Training Loss:  [0.05214383]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  165\n",
      "Training Loss:  [0.0519668]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  166\n",
      "Training Loss:  [0.05179037]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  167\n",
      "Training Loss:  [0.05161456]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  168\n",
      "Training Loss:  [0.05143935]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  169\n",
      "Training Loss:  [0.05126474]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  170\n",
      "Training Loss:  [0.05109073]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  171\n",
      "Training Loss:  [0.05091732]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  172\n",
      "Training Loss:  [0.0507445]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  173\n",
      "Training Loss:  [0.05057227]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  174\n",
      "Training Loss:  [0.05040063]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  175\n",
      "Training Loss:  [0.05022958]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  176\n",
      "Training Loss:  [0.05005911]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  177\n",
      "Training Loss:  [0.04988923]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  178\n",
      "Training Loss:  [0.04971992]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  179\n",
      "Training Loss:  [0.0495512]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  180\n",
      "Training Loss:  [0.04938305]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  181\n",
      "Training Loss:  [0.04921548]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  182\n",
      "Training Loss:  [0.04904848]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  183\n",
      "Training Loss:  [0.04888205]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  184\n",
      "Training Loss:  [0.0487162]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  185\n",
      "Training Loss:  [0.04855091]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  186\n",
      "Training Loss:  [0.04838619]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  187\n",
      "Training Loss:  [0.04822203]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  188\n",
      "Training Loss:  [0.04805844]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  189\n",
      "Training Loss:  [0.04789541]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  190\n",
      "Training Loss:  [0.04773294]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  191\n",
      "Training Loss:  [0.04757103]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  192\n",
      "Training Loss:  [0.04740968]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  193\n",
      "Training Loss:  [0.04724888]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  194\n",
      "Training Loss:  [0.04708865]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  195\n",
      "Training Loss:  [0.04692896]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  196\n",
      "Training Loss:  [0.04676983]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  197\n",
      "Training Loss:  [0.04661126]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  198\n",
      "Training Loss:  [0.04645323]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  199\n",
      "Training Loss:  [0.04629575]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1] [1]\n",
      "Training Loss:  [0.04629575]\n",
      "Training Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train), model.predict(np.array([[1,1]])))\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.45246857, 1.70944295]])]\n",
      "[array([-0.29142836])]\n"
     ]
    }
   ],
   "source": [
    "print(model.weights)\n",
    "print(model.biases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
