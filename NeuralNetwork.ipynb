{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoded(y_train, classes = 0):\n",
    "    one_hot = np.zeros((len(y_train), classes))\n",
    "    array = y_train\n",
    "    if type(array) is not np.ndarray: \n",
    "        array = np.array(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        one_hot[i][array[i]] = 1.0\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.num_layers = 0\n",
    "        self.layers_info = {}\n",
    "        self.layers = []\n",
    "        self.net_sum = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.jacobian_weights = []\n",
    "        self.jacobian_biases = []\n",
    "    \n",
    "    # Add a fully connected layer\n",
    "    def add_dense_layer(self, size, input_size = 0, activation = 'linear'):\n",
    "        self.num_layers += 1\n",
    "        self.layers_info['Layer_'+str(self.num_layers)] = {\n",
    "            'size': size,\n",
    "            'activation': activation\n",
    "        }\n",
    "        self.layers.append(np.ones(size))\n",
    "        self.net_sum.append(np.ones(size))\n",
    "        if input_size != 0:\n",
    "            self.weights.append(np.random.randn(size, input_size) * np.sqrt(2/(size+input_size)))\n",
    "        else:\n",
    "            input_size = self.layers_info['Layer_'+str(self.num_layers-1)]['size']\n",
    "            self.weights.append(np.random.randn(size, input_size) * np.sqrt(2/(size+input_size)))\n",
    "        self.biases.append(np.random.randn(size) * np.sqrt(1/size))\n",
    "        \n",
    "    def mse(self, true, pred):\n",
    "        return ((true-pred)**2)/2\n",
    "        \n",
    "    # Selection of Loss Function and Optimization function\n",
    "    def set_parameters(self, lr = 0.01, loss = 'mse'):\n",
    "        if loss == 'mse':\n",
    "            self.loss = loss\n",
    "            self.loss_function = self.mse\n",
    "        self.lr = lr\n",
    "    \n",
    "    # Sigmoid\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + (np.e ** -x))\n",
    "    \n",
    "    # ReLU - Rectified Linear Unit\n",
    "    def relu(self, x):\n",
    "        return max(0, x)\n",
    "    \n",
    "    # Softmax\n",
    "    def softmax(self, x):\n",
    "        exp = np.exp(x)\n",
    "        return np.true_divide(exp, sum(exp)).transpose()\n",
    "    \n",
    "    def activation(self, net_sum, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            activation_function = self.sigmoid\n",
    "            output_vector = np.array([activation_function(i) for i in net_sum]).transpose()\n",
    "        elif activation == 'relu':\n",
    "            activation_function = self.relu\n",
    "            output_vector = np.array([activation_function(i) for i in net_sum]).transpose()\n",
    "        elif activation == 'softmax':\n",
    "            activation_function = self.softmax\n",
    "            output_vector = activation_function(net_sum)\n",
    "        return output_vector\n",
    "    \n",
    "    # Forward Propogation\n",
    "    def neural_network_output(self, record):\n",
    "        input_vector = record.transpose()\n",
    "        output_vector = None\n",
    "        for i in range(len(self.layers)):\n",
    "            # y = aW + b\n",
    "            self.net_sum[i] = np.matmul(self.weights[i], input_vector) + self.biases[i].transpose()\n",
    "            self.layers[i] = self.activation(self.net_sum[i], self.layers_info['Layer_'+str(i+1)]['activation'])\n",
    "            input_vector = self.layers[i]\n",
    "        output_vector = self.layers[len(self.layers)-1]\n",
    "        return output_vector\n",
    "    \n",
    "    # For output layer\n",
    "    # delta = dE/dnet_sum_output = dE/doutput * doutput/dnet_sum_output\n",
    "    # dE/doutput\n",
    "    def output_loss_derivative(self, true, pred):\n",
    "        if self.loss == 'mse':\n",
    "            return (true - pred)\n",
    "    \n",
    "    # doutput/dnet_sum_output\n",
    "    def activation_derivative(self, output_vector_i, net_sum_i, activation):\n",
    "        if activation == 'relu':\n",
    "            return np.array([1 if i>0 else 0 for i in net_sum_i])\n",
    "        elif activation == 'sigmoid':\n",
    "            return output_vector_i * (1 - output_vector_i)\n",
    "        elif activation == 'softmax':\n",
    "            return output_vector_i * (1 - output_vector_i)\n",
    "        else:\n",
    "            return output_vector_i * (1 - output_vector_i)\n",
    "    \n",
    "    # For hidden layer\n",
    "    # dE/dnet_sum_hidden = dotproduct(weights_ji, delta_o)\n",
    "    def hidden_loss_derivative(self, grad_next, layer_number, num_of_neurons_next):\n",
    "        grad = []\n",
    "        for i in range(num_of_neurons_next):\n",
    "            weights_next = self.weights[layer_number+1][:, i]\n",
    "            grad.append(np.dot(weights_next, grad_next))\n",
    "        return np.array(grad)\n",
    "    \n",
    "    # Training using Backpropogation\n",
    "    def train(self, X_train, y_train, epochs = 1, batch_size = 0): \n",
    "        \n",
    "        # initializing Jacobian\n",
    "        for i in range(self.num_layers):\n",
    "            size = self.layers_info['Layer_'+str(i+1)]['size']            \n",
    "            input_size = 0\n",
    "            self.jacobian_biases.append(np.zeros((size)))\n",
    "            if i == 0:\n",
    "                input_size = X_train.shape[1]\n",
    "            else:\n",
    "                input_size = len(self.layers[i-1])\n",
    "            self.jacobian_weights.append(np.zeros((size, input_size)))\n",
    "        \n",
    "        # Creation of batches\n",
    "        self.x = X_train\n",
    "        self.y = y_train\n",
    "        if batch_size == 0:\n",
    "            batch_size = len(y_train)\n",
    "        batches = int(abs(len(X_train) / batch_size))\n",
    "        X_train = np.array_split(X_train, batches)\n",
    "        y_train = np.array_split(y_train, batches)\n",
    "        \n",
    "        for epoch in range(epochs): \n",
    "            for batch in range(batches):\n",
    "                for record, label in zip(X_train[batch], y_train[batch]):\n",
    "                    true_output = np.array([label])\n",
    "                    predicted_output = self.neural_network_output(np.array(record))\n",
    "\n",
    "                    # gradient of output layer\n",
    "                    output_vector_i = self.layers[self.num_layers-1]\n",
    "                    net_sum_i = self.net_sum[self.num_layers-1]\n",
    "                    activation = self.layers_info['Layer_'+str(self.num_layers)]['activation']\n",
    "                    # derivative of output loss * derivetive of activation\n",
    "                    grad_o = self.output_loss_derivative(true_output, predicted_output) * self.activation_derivative(output_vector_i, net_sum_i, activation)\n",
    "                    \n",
    "                    # Jacobian Output Layer - Jw = input * grad_o and Jb = 1.0 * grad_o\n",
    "                    if self.num_layers-2 < 0:\n",
    "                        self.jacobian_weights[self.num_layers-1] += np.array(record) * grad_o\n",
    "                    \n",
    "                    self.jacobian_weights[self.num_layers-1] += grad_o[:, None] @ self.layers[self.num_layers-2][None, :]\n",
    "                    self.jacobian_biases[self.num_layers-1] += grad_o\n",
    "                    \n",
    "                    # gradient of hidden layer\n",
    "                    grad_next = grad_o\n",
    "                    for i in range(self.num_layers-2, -1, -1):\n",
    "                        output_vector_i = self.layers[i]\n",
    "                        net_sum_i = self.layers[i]\n",
    "                        activation = self.layers_info['Layer_'+str(i+1)]['activation']\n",
    "                        num_of_neurons_next = self.layers_info['Layer_'+str(i+2)]['size']\n",
    "                        \n",
    "                        # derivative of hidden loss * derivetive of activation\n",
    "                        grad_h = self.hidden_loss_derivative(grad_next, i, num_of_neurons_next) * self.activation_derivative(output_vector_i, net_sum_i, activation)\n",
    "                        \n",
    "                        # Jacobian Hidden layer - Jw = input * grad_next and Jb = 1.0 * grad_next\n",
    "                        if i-1 < 0:\n",
    "                            self.jacobian_weights[i] += grad_h[:, None] @ np.array(record)[None, :]\n",
    "                        self.jacobian_weights[i] += grad_h[:, None] @ self.layers[i-1][None, :]\n",
    "                        self.jacobian_biases[i] += grad_h\n",
    "                        \n",
    "                        # change the gradient\n",
    "                        grad_next = grad_h\n",
    "                \n",
    "                # Divide accumulated jacobian by number of records in the batch\n",
    "                for i in range(self.num_layers):\n",
    "                    self.jacobian_weights[i] = self.jacobian_weights[i] / len(record)\n",
    "                    self.jacobian_biases[i] = self.jacobian_biases[i] / len(record)\n",
    "                \n",
    "                # Update weights and biases\n",
    "                for i in range(self.num_layers-1, -1, -1):\n",
    "                    self.weights[i] += self.lr * self.jacobian_weights[i]\n",
    "                    self.biases[i] += self.lr * self.jacobian_biases[i]\n",
    "            \n",
    "            # Accuracy and Loss\n",
    "            print('Epoch ',epoch)\n",
    "            self.evaluate(self.x, self.y)\n",
    "            print('')\n",
    "            \n",
    "    \n",
    "    # Predict\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        classes = self.layers_info['Layer_'+str(self.num_layers)]['size']\n",
    "        for record in X_test:\n",
    "            predicted_output = self.neural_network_output(record)\n",
    "            if classes == 1:\n",
    "                if predicted_output[0] >= 0.5:\n",
    "                    predictions.append(1)\n",
    "                else:\n",
    "                    predictions.append(0)\n",
    "            else:\n",
    "                predict = np.argmax(predicted_output)\n",
    "                predictions.append(predict)\n",
    "        return predictions\n",
    "    \n",
    "    # Accuracy and Loss\n",
    "    def evaluate(self, X_test, y_test):       \n",
    "        # Loss\n",
    "        loss = 0\n",
    "        for record, label in zip(X_test, y_test):\n",
    "            true_output = label\n",
    "            predicted_output = self.neural_network_output(record)\n",
    "            loss += self.loss_function(true_output, predicted_output)\n",
    "        print('Training Loss: ',loss/len(X_test))\n",
    "        \n",
    "        # Accuracy\n",
    "        true_output = y_test\n",
    "        predicted_output = self.predict(X_test)\n",
    "        x = np.logical_not(np.logical_xor(true_output, predicted_output))\n",
    "        accuracy = len(x[x==True])/len(x)\n",
    "        print('Training Accuracy: ',accuracy)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed-froward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "model.add_dense_layer(4, 3, activation='relu')\n",
    "model.add_dense_layer(1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Dataset - XOR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [0, 1, 0], [1, 0, 0], [1, 1, 1], [0, 0, 0]])\n",
    "y_train = np.array([0, 1, 1, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Hyperparameters: <br>\n",
    "Loss Function: Mean Square Error(mse) <br> \n",
    "Learning rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_parameters(lr=0.1, loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Training Loss:  [0.13019199]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  1\n",
      "Training Loss:  [0.12986797]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  2\n",
      "Training Loss:  [0.12953848]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  3\n",
      "Training Loss:  [0.12922367]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  4\n",
      "Training Loss:  [0.12892888]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  5\n",
      "Training Loss:  [0.12865461]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  6\n",
      "Training Loss:  [0.12839982]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  7\n",
      "Training Loss:  [0.12816306]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  8\n",
      "Training Loss:  [0.12794284]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  9\n",
      "Training Loss:  [0.12773776]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  10\n",
      "Training Loss:  [0.12754651]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  11\n",
      "Training Loss:  [0.12736791]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  12\n",
      "Training Loss:  [0.12720088]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  13\n",
      "Training Loss:  [0.12704441]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  14\n",
      "Training Loss:  [0.12689761]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  15\n",
      "Training Loss:  [0.12675964]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  16\n",
      "Training Loss:  [0.12662977]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  17\n",
      "Training Loss:  [0.12650729]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  18\n",
      "Training Loss:  [0.12639159]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  19\n",
      "Training Loss:  [0.12628208]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  20\n",
      "Training Loss:  [0.12617825]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  21\n",
      "Training Loss:  [0.12607961]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  22\n",
      "Training Loss:  [0.12598573]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  23\n",
      "Training Loss:  [0.12589619]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  24\n",
      "Training Loss:  [0.12581064]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  25\n",
      "Training Loss:  [0.12572874]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  26\n",
      "Training Loss:  [0.12565017]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  27\n",
      "Training Loss:  [0.12557466]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  28\n",
      "Training Loss:  [0.12550194]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  29\n",
      "Training Loss:  [0.12543177]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  30\n",
      "Training Loss:  [0.12536394]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  31\n",
      "Training Loss:  [0.12529824]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  32\n",
      "Training Loss:  [0.12523449]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  33\n",
      "Training Loss:  [0.12517251]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  34\n",
      "Training Loss:  [0.12511216]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  35\n",
      "Training Loss:  [0.12505328]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  36\n",
      "Training Loss:  [0.12499575]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  37\n",
      "Training Loss:  [0.12493944]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  38\n",
      "Training Loss:  [0.12488423]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  39\n",
      "Training Loss:  [0.12483003]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  40\n",
      "Training Loss:  [0.12477674]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  41\n",
      "Training Loss:  [0.12472426]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  42\n",
      "Training Loss:  [0.12467252]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  43\n",
      "Training Loss:  [0.12462144]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  44\n",
      "Training Loss:  [0.12457095]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  45\n",
      "Training Loss:  [0.12452098]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  46\n",
      "Training Loss:  [0.12447148]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  47\n",
      "Training Loss:  [0.12442238]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  48\n",
      "Training Loss:  [0.12437364]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  49\n",
      "Training Loss:  [0.12432521]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  50\n",
      "Training Loss:  [0.12427704]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  51\n",
      "Training Loss:  [0.12422908]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  52\n",
      "Training Loss:  [0.12418131]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  53\n",
      "Training Loss:  [0.12413368]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  54\n",
      "Training Loss:  [0.12408617]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  55\n",
      "Training Loss:  [0.12403873]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  56\n",
      "Training Loss:  [0.12399134]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  57\n",
      "Training Loss:  [0.12394397]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  58\n",
      "Training Loss:  [0.12389659]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  59\n",
      "Training Loss:  [0.12384918]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  60\n",
      "Training Loss:  [0.12380172]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  61\n",
      "Training Loss:  [0.12375419]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  62\n",
      "Training Loss:  [0.12370656]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  63\n",
      "Training Loss:  [0.12365881]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  64\n",
      "Training Loss:  [0.12363736]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  65\n",
      "Training Loss:  [0.12371022]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  66\n",
      "Training Loss:  [0.12380645]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  67\n",
      "Training Loss:  [0.12391085]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  68\n",
      "Training Loss:  [0.12401834]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  69\n",
      "Training Loss:  [0.1241272]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  70\n",
      "Training Loss:  [0.12423686]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  71\n",
      "Training Loss:  [0.12434711]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  72\n",
      "Training Loss:  [0.12445786]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  73\n",
      "Training Loss:  [0.12456909]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  74\n",
      "Training Loss:  [0.12468075]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  75\n",
      "Training Loss:  [0.12479283]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  76\n",
      "Training Loss:  [0.1249053]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  77\n",
      "Training Loss:  [0.12501812]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  78\n",
      "Training Loss:  [0.12513128]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  79\n",
      "Training Loss:  [0.12524473]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  80\n",
      "Training Loss:  [0.12535845]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  81\n",
      "Training Loss:  [0.12547239]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  82\n",
      "Training Loss:  [0.12558652]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  83\n",
      "Training Loss:  [0.1257008]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  84\n",
      "Training Loss:  [0.12581518]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  85\n",
      "Training Loss:  [0.12592962]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  86\n",
      "Training Loss:  [0.12604406]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  87\n",
      "Training Loss:  [0.12615846]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  88\n",
      "Training Loss:  [0.12627276]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  89\n",
      "Training Loss:  [0.1263869]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  90\n",
      "Training Loss:  [0.12650083]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  91\n",
      "Training Loss:  [0.12661447]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  92\n",
      "Training Loss:  [0.12672778]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  93\n",
      "Training Loss:  [0.12684066]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  94\n",
      "Training Loss:  [0.12695307]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  95\n",
      "Training Loss:  [0.12706491]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  96\n",
      "Training Loss:  [0.12717612]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  97\n",
      "Training Loss:  [0.12728661]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  98\n",
      "Training Loss:  [0.1273963]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  99\n",
      "Training Loss:  [0.12750511]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  100\n",
      "Training Loss:  [0.12761295]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  101\n",
      "Training Loss:  [0.12771971]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  102\n",
      "Training Loss:  [0.12782532]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  103\n",
      "Training Loss:  [0.12792966]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  104\n",
      "Training Loss:  [0.12803265]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  105\n",
      "Training Loss:  [0.12813417]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  106\n",
      "Training Loss:  [0.12823413]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  107\n",
      "Training Loss:  [0.1283324]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  108\n",
      "Training Loss:  [0.12842888]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  109\n",
      "Training Loss:  [0.12852346]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  110\n",
      "Training Loss:  [0.12861601]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  111\n",
      "Training Loss:  [0.12870641]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  112\n",
      "Training Loss:  [0.12879455]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  113\n",
      "Training Loss:  [0.1288803]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  114\n",
      "Training Loss:  [0.12896352]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  115\n",
      "Training Loss:  [0.12904409]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  116\n",
      "Training Loss:  [0.12912188]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  117\n",
      "Training Loss:  [0.12916886]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  118\n",
      "Training Loss:  [0.12912486]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  119\n",
      "Training Loss:  [0.12906101]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  120\n",
      "Training Loss:  [0.12898918]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  121\n",
      "Training Loss:  [0.12891329]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  122\n",
      "Training Loss:  [0.12883462]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  123\n",
      "Training Loss:  [0.12875357]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  124\n",
      "Training Loss:  [0.12867022]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  125\n",
      "Training Loss:  [0.12858457]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  126\n",
      "Training Loss:  [0.12849659]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  127\n",
      "Training Loss:  [0.12840626]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  128\n",
      "Training Loss:  [0.12831351]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  129\n",
      "Training Loss:  [0.12821832]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  130\n",
      "Training Loss:  [0.12812065]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  131\n",
      "Training Loss:  [0.12802045]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  132\n",
      "Training Loss:  [0.12791771]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  133\n",
      "Training Loss:  [0.12779764]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  134\n",
      "Training Loss:  [0.12761953]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  135\n",
      "Training Loss:  [0.12742534]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  136\n",
      "Training Loss:  [0.1272614]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  137\n",
      "Training Loss:  [0.12708055]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  138\n",
      "Training Loss:  [0.12687485]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  139\n",
      "Training Loss:  [0.12671758]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  140\n",
      "Training Loss:  [0.12652792]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  141\n",
      "Training Loss:  [0.12635123]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  142\n",
      "Training Loss:  [0.12616653]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  143\n",
      "Training Loss:  [0.12596477]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  144\n",
      "Training Loss:  [0.12579472]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  145\n",
      "Training Loss:  [0.12560444]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  146\n",
      "Training Loss:  [0.12541882]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  147\n",
      "Training Loss:  [0.12523]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  148\n",
      "Training Loss:  [0.12502241]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  149\n",
      "Training Loss:  [0.12484915]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  150\n",
      "Training Loss:  [0.12464873]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  151\n",
      "Training Loss:  [0.12446374]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  152\n",
      "Training Loss:  [0.12427083]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  153\n",
      "Training Loss:  [0.12404851]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  154\n",
      "Training Loss:  [0.12387745]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  155\n",
      "Training Loss:  [0.12368144]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  156\n",
      "Training Loss:  [0.12348471]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  157\n",
      "Training Loss:  [0.12328292]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  158\n",
      "Training Loss:  [0.12308735]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  159\n",
      "Training Loss:  [0.12288661]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  160\n",
      "Training Loss:  [0.12268506]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  161\n",
      "Training Loss:  [0.12249148]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  162\n",
      "Training Loss:  [0.12225005]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  163\n",
      "Training Loss:  [0.12206465]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  164\n",
      "Training Loss:  [0.12185615]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  165\n",
      "Training Loss:  [0.12164901]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  166\n",
      "Training Loss:  [0.1214269]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  167\n",
      "Training Loss:  [0.12124056]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  168\n",
      "Training Loss:  [0.12100115]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  169\n",
      "Training Loss:  [0.12080398]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  170\n",
      "Training Loss:  [0.12058491]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  171\n",
      "Training Loss:  [0.12037102]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  172\n",
      "Training Loss:  [0.12014514]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  173\n",
      "Training Loss:  [0.11994124]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  174\n",
      "Training Loss:  [0.11970753]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  175\n",
      "Training Loss:  [0.1194949]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  176\n",
      "Training Loss:  [0.11927048]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  177\n",
      "Training Loss:  [0.11906294]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  178\n",
      "Training Loss:  [0.1188236]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  179\n",
      "Training Loss:  [0.11860536]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  180\n",
      "Training Loss:  [0.11837753]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  181\n",
      "Training Loss:  [0.11816807]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  182\n",
      "Training Loss:  [0.11792121]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  183\n",
      "Training Loss:  [0.11770107]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  184\n",
      "Training Loss:  [0.11746662]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  185\n",
      "Training Loss:  [0.11725619]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  186\n",
      "Training Loss:  [0.11700141]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  187\n",
      "Training Loss:  [0.11678285]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  188\n",
      "Training Loss:  [0.1165389]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  189\n",
      "Training Loss:  [0.11632603]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  190\n",
      "Training Loss:  [0.11607821]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  191\n",
      "Training Loss:  [0.11584767]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  192\n",
      "Training Loss:  [0.1155999]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  193\n",
      "Training Loss:  [0.11537804]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  194\n",
      "Training Loss:  [0.11515202]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  195\n",
      "Training Loss:  [0.11490666]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  196\n",
      "Training Loss:  [0.11466655]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  197\n",
      "Training Loss:  [0.1144291]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  198\n",
      "Training Loss:  [0.11419759]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  199\n",
      "Training Loss:  [0.11395019]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  200\n",
      "Training Loss:  [0.11372689]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  201\n",
      "Training Loss:  [0.11347588]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  202\n",
      "Training Loss:  [0.11321678]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  203\n",
      "Training Loss:  [0.11299445]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  204\n",
      "Training Loss:  [0.11275795]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  205\n",
      "Training Loss:  [0.11252291]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  206\n",
      "Training Loss:  [0.11228685]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  207\n",
      "Training Loss:  [0.11203137]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  208\n",
      "Training Loss:  [0.11178903]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  209\n",
      "Training Loss:  [0.11154554]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  210\n",
      "Training Loss:  [0.11130534]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  211\n",
      "Training Loss:  [0.11109154]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  212\n",
      "Training Loss:  [0.11088285]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  213\n",
      "Training Loss:  [0.11065348]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  214\n",
      "Training Loss:  [0.11046626]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  215\n",
      "Training Loss:  [0.11020593]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  216\n",
      "Training Loss:  [0.10999486]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  217\n",
      "Training Loss:  [0.10979185]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  218\n",
      "Training Loss:  [0.10956791]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  219\n",
      "Training Loss:  [0.10933598]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  220\n",
      "Training Loss:  [0.10916931]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  221\n",
      "Training Loss:  [0.10891924]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  222\n",
      "Training Loss:  [0.10870235]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  223\n",
      "Training Loss:  [0.10854482]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  224\n",
      "Training Loss:  [0.10827671]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  225\n",
      "Training Loss:  [0.10812098]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  226\n",
      "Training Loss:  [0.10784271]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  227\n",
      "Training Loss:  [0.10762781]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  228\n",
      "Training Loss:  [0.1074405]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  229\n",
      "Training Loss:  [0.10727527]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  230\n",
      "Training Loss:  [0.10701203]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  231\n",
      "Training Loss:  [0.10687841]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  232\n",
      "Training Loss:  [0.10660558]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  233\n",
      "Training Loss:  [0.10648806]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  234\n",
      "Training Loss:  [0.10624066]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  235\n",
      "Training Loss:  [0.10602385]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  236\n",
      "Training Loss:  [0.1057774]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  237\n",
      "Training Loss:  [0.10558848]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  238\n",
      "Training Loss:  [0.10543129]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  239\n",
      "Training Loss:  [0.10516618]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  240\n",
      "Training Loss:  [0.10508608]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  241\n",
      "Training Loss:  [0.10482548]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  242\n",
      "Training Loss:  [0.10461098]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  243\n",
      "Training Loss:  [0.10440084]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  244\n",
      "Training Loss:  [0.10418434]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  245\n",
      "Training Loss:  [0.10400367]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  246\n",
      "Training Loss:  [0.10384258]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  247\n",
      "Training Loss:  [0.10359285]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  248\n",
      "Training Loss:  [0.10346587]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  249\n",
      "Training Loss:  [0.10320523]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  250\n",
      "Training Loss:  [0.10306851]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  251\n",
      "Training Loss:  [0.10283176]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  252\n",
      "Training Loss:  [0.10268187]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  253\n",
      "Training Loss:  [0.10245848]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  254\n",
      "Training Loss:  [0.1022506]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  255\n",
      "Training Loss:  [0.10210263]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  256\n",
      "Training Loss:  [0.10192383]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  257\n",
      "Training Loss:  [0.10172664]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  258\n",
      "Training Loss:  [0.10154653]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  259\n",
      "Training Loss:  [0.10136584]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  260\n",
      "Training Loss:  [0.10117047]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  261\n",
      "Training Loss:  [0.10101565]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  262\n",
      "Training Loss:  [0.10080518]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  263\n",
      "Training Loss:  [0.10061273]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  264\n",
      "Training Loss:  [0.10051297]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  265\n",
      "Training Loss:  [0.10025489]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  266\n",
      "Training Loss:  [0.10012943]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  267\n",
      "Training Loss:  [0.0998956]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  268\n",
      "Training Loss:  [0.09985479]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  269\n",
      "Training Loss:  [0.09958646]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  270\n",
      "Training Loss:  [0.09945049]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  271\n",
      "Training Loss:  [0.09923696]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  272\n",
      "Training Loss:  [0.09910405]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  273\n",
      "Training Loss:  [0.0989125]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  274\n",
      "Training Loss:  [0.09868751]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  275\n",
      "Training Loss:  [0.09859665]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  276\n",
      "Training Loss:  [0.09835044]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  277\n",
      "Training Loss:  [0.09820882]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  278\n",
      "Training Loss:  [0.09800886]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  279\n",
      "Training Loss:  [0.09784627]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  280\n",
      "Training Loss:  [0.09766053]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  281\n",
      "Training Loss:  [0.09755631]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  282\n",
      "Training Loss:  [0.09732787]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  283\n",
      "Training Loss:  [0.09725009]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  284\n",
      "Training Loss:  [0.09699821]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  285\n",
      "Training Loss:  [0.09688852]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  286\n",
      "Training Loss:  [0.09668355]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  287\n",
      "Training Loss:  [0.09660308]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  288\n",
      "Training Loss:  [0.09634782]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  289\n",
      "Training Loss:  [0.09624895]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  290\n",
      "Training Loss:  [0.09603226]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  291\n",
      "Training Loss:  [0.09590112]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  292\n",
      "Training Loss:  [0.0956985]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  293\n",
      "Training Loss:  [0.09569569]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  294\n",
      "Training Loss:  [0.0953952]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  295\n",
      "Training Loss:  [0.09530013]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  296\n",
      "Training Loss:  [0.09510728]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  297\n",
      "Training Loss:  [0.09502962]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  298\n",
      "Training Loss:  [0.09479473]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  299\n",
      "Training Loss:  [0.09468005]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  300\n",
      "Training Loss:  [0.09449435]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  301\n",
      "Training Loss:  [0.09440262]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  302\n",
      "Training Loss:  [0.09422738]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  303\n",
      "Training Loss:  [0.09404789]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  304\n",
      "Training Loss:  [0.09400794]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  305\n",
      "Training Loss:  [0.09375446]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  306\n",
      "Training Loss:  [0.09366918]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  307\n",
      "Training Loss:  [0.09346103]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  308\n",
      "Training Loss:  [0.09338515]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  309\n",
      "Training Loss:  [0.09317092]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  310\n",
      "Training Loss:  [0.09309141]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  311\n",
      "Training Loss:  [0.09290622]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  312\n",
      "Training Loss:  [0.09281764]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  313\n",
      "Training Loss:  [0.09262879]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  314\n",
      "Training Loss:  [0.09246638]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  315\n",
      "Training Loss:  [0.09235652]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  316\n",
      "Training Loss:  [0.09217733]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  317\n",
      "Training Loss:  [0.09207628]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  318\n",
      "Training Loss:  [0.09189302]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  319\n",
      "Training Loss:  [0.09179187]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  320\n",
      "Training Loss:  [0.09161831]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  321\n",
      "Training Loss:  [0.09150864]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  322\n",
      "Training Loss:  [0.09134402]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  323\n",
      "Training Loss:  [0.09128484]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  324\n",
      "Training Loss:  [0.09112338]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  325\n",
      "Training Loss:  [0.09093695]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  326\n",
      "Training Loss:  [0.09082086]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  327\n",
      "Training Loss:  [0.09067948]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  328\n",
      "Training Loss:  [0.09059355]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  329\n",
      "Training Loss:  [0.09043686]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  330\n",
      "Training Loss:  [0.09027362]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  331\n",
      "Training Loss:  [0.09014314]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  332\n",
      "Training Loss:  [0.09000012]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  333\n",
      "Training Loss:  [0.08987717]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  334\n",
      "Training Loss:  [0.08970797]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  335\n",
      "Training Loss:  [0.08961528]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  336\n",
      "Training Loss:  [0.08945015]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  337\n",
      "Training Loss:  [0.08932623]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  338\n",
      "Training Loss:  [0.08921561]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  339\n",
      "Training Loss:  [0.08904811]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  340\n",
      "Training Loss:  [0.08902709]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  341\n",
      "Training Loss:  [0.08880664]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  342\n",
      "Training Loss:  [0.08865086]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  343\n",
      "Training Loss:  [0.08861154]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  344\n",
      "Training Loss:  [0.08837433]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  345\n",
      "Training Loss:  [0.08831076]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  346\n",
      "Training Loss:  [0.08815143]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  347\n",
      "Training Loss:  [0.08797566]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  348\n",
      "Training Loss:  [0.0878683]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  349\n",
      "Training Loss:  [0.08769887]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  350\n",
      "Training Loss:  [0.0877074]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  351\n",
      "Training Loss:  [0.08746102]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  352\n",
      "Training Loss:  [0.08730764]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  353\n",
      "Training Loss:  [0.08725613]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  354\n",
      "Training Loss:  [0.08703007]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  355\n",
      "Training Loss:  [0.0869432]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  356\n",
      "Training Loss:  [0.08678299]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  357\n",
      "Training Loss:  [0.08661758]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  358\n",
      "Training Loss:  [0.08662586]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  359\n",
      "Training Loss:  [0.0863819]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  360\n",
      "Training Loss:  [0.08622921]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  361\n",
      "Training Loss:  [0.08615179]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  362\n",
      "Training Loss:  [0.08595515]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  363\n",
      "Training Loss:  [0.08581843]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  364\n",
      "Training Loss:  [0.0857062]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  365\n",
      "Training Loss:  [0.08553943]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  366\n",
      "Training Loss:  [0.08546416]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  367\n",
      "Training Loss:  [0.08530678]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  368\n",
      "Training Loss:  [0.08514981]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  369\n",
      "Training Loss:  [0.08498192]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  370\n",
      "Training Loss:  [0.08487099]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  371\n",
      "Training Loss:  [0.08470135]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  372\n",
      "Training Loss:  [0.08463319]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  373\n",
      "Training Loss:  [0.08441954]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  374\n",
      "Training Loss:  [0.08427217]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  375\n",
      "Training Loss:  [0.08416621]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  376\n",
      "Training Loss:  [0.08399834]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  377\n",
      "Training Loss:  [0.08388133]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  378\n",
      "Training Loss:  [0.08376108]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  379\n",
      "Training Loss:  [0.08360433]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  380\n",
      "Training Loss:  [0.08340851]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  381\n",
      "Training Loss:  [0.0833851]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  382\n",
      "Training Loss:  [0.08311661]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  383\n",
      "Training Loss:  [0.08300658]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  384\n",
      "Training Loss:  [0.08285566]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  385\n",
      "Training Loss:  [0.08268297]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  386\n",
      "Training Loss:  [0.08257981]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  387\n",
      "Training Loss:  [0.08239254]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  388\n",
      "Training Loss:  [0.08221975]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  389\n",
      "Training Loss:  [0.0821958]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  390\n",
      "Training Loss:  [0.08197057]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  391\n",
      "Training Loss:  [0.08181666]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  392\n",
      "Training Loss:  [0.08160932]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  393\n",
      "Training Loss:  [0.08162756]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  394\n",
      "Training Loss:  [0.0813062]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  395\n",
      "Training Loss:  [0.08120687]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  396\n",
      "Training Loss:  [0.08103962]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  397\n",
      "Training Loss:  [0.08088321]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  398\n",
      "Training Loss:  [0.08073614]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  399\n",
      "Training Loss:  [0.08057175]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  400\n",
      "Training Loss:  [0.08038686]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  401\n",
      "Training Loss:  [0.08029785]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  402\n",
      "Training Loss:  [0.08014481]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  403\n",
      "Training Loss:  [0.0799875]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  404\n",
      "Training Loss:  [0.07980994]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  405\n",
      "Training Loss:  [0.07975354]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  406\n",
      "Training Loss:  [0.07951717]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  407\n",
      "Training Loss:  [0.07935075]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  408\n",
      "Training Loss:  [0.07934839]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  409\n",
      "Training Loss:  [0.07908324]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  410\n",
      "Training Loss:  [0.07892243]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  411\n",
      "Training Loss:  [0.07890413]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  412\n",
      "Training Loss:  [0.07870533]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  413\n",
      "Training Loss:  [0.07855022]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  414\n",
      "Training Loss:  [0.07837321]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  415\n",
      "Training Loss:  [0.07831119]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  416\n",
      "Training Loss:  [0.07808706]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  417\n",
      "Training Loss:  [0.07791486]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  418\n",
      "Training Loss:  [0.077852]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  419\n",
      "Training Loss:  [0.07766536]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  420\n",
      "Training Loss:  [0.07748334]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  421\n",
      "Training Loss:  [0.07739138]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  422\n",
      "Training Loss:  [0.07723469]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  423\n",
      "Training Loss:  [0.07706759]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  424\n",
      "Training Loss:  [0.07689352]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  425\n",
      "Training Loss:  [0.07679512]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  426\n",
      "Training Loss:  [0.07664393]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  427\n",
      "Training Loss:  [0.07643636]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  428\n",
      "Training Loss:  [0.07645896]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  429\n",
      "Training Loss:  [0.07622313]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  430\n",
      "Training Loss:  [0.07605842]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  431\n",
      "Training Loss:  [0.07586915]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  432\n",
      "Training Loss:  [0.07576936]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  433\n",
      "Training Loss:  [0.07559453]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  434\n",
      "Training Loss:  [0.07543086]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  435\n",
      "Training Loss:  [0.07524445]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  436\n",
      "Training Loss:  [0.07517112]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  437\n",
      "Training Loss:  [0.0750077]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  438\n",
      "Training Loss:  [0.07480317]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  439\n",
      "Training Loss:  [0.07478037]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  440\n",
      "Training Loss:  [0.07457127]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  441\n",
      "Training Loss:  [0.07442463]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  442\n",
      "Training Loss:  [0.0742269]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  443\n",
      "Training Loss:  [0.07406512]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  444\n",
      "Training Loss:  [0.07396274]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  445\n",
      "Training Loss:  [0.07378193]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  446\n",
      "Training Loss:  [0.07358059]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  447\n",
      "Training Loss:  [0.07357592]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  448\n",
      "Training Loss:  [0.07330921]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  449\n",
      "Training Loss:  [0.07313948]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  450\n",
      "Training Loss:  [0.07299808]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  451\n",
      "Training Loss:  [0.07289109]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  452\n",
      "Training Loss:  [0.07271656]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  453\n",
      "Training Loss:  [0.0725178]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  454\n",
      "Training Loss:  [0.07247583]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  455\n",
      "Training Loss:  [0.07227473]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  456\n",
      "Training Loss:  [0.07215869]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  457\n",
      "Training Loss:  [0.07194269]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  458\n",
      "Training Loss:  [0.07172403]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  459\n",
      "Training Loss:  [0.07180805]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  460\n",
      "Training Loss:  [0.0714399]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  461\n",
      "Training Loss:  [0.07128167]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  462\n",
      "Training Loss:  [0.07118924]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  463\n",
      "Training Loss:  [0.07100441]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  464\n",
      "Training Loss:  [0.0708567]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  465\n",
      "Training Loss:  [0.07064228]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  466\n",
      "Training Loss:  [0.07062938]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  467\n",
      "Training Loss:  [0.07040248]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  468\n",
      "Training Loss:  [0.07029521]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  469\n",
      "Training Loss:  [0.07006421]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  470\n",
      "Training Loss:  [0.06986157]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  471\n",
      "Training Loss:  [0.06994847]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  472\n",
      "Training Loss:  [0.06956151]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  473\n",
      "Training Loss:  [0.06939901]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  474\n",
      "Training Loss:  [0.06930029]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  475\n",
      "Training Loss:  [0.06914356]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  476\n",
      "Training Loss:  [0.06897663]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  477\n",
      "Training Loss:  [0.06875948]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  478\n",
      "Training Loss:  [0.06871553]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  479\n",
      "Training Loss:  [0.0684757]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  480\n",
      "Training Loss:  [0.06835776]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  481\n",
      "Training Loss:  [0.06812029]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  482\n",
      "Training Loss:  [0.06818516]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  483\n",
      "Training Loss:  [0.06789504]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  484\n",
      "Training Loss:  [0.0677321]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  485\n",
      "Training Loss:  [0.06752154]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  486\n",
      "Training Loss:  [0.06733849]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  487\n",
      "Training Loss:  [0.06725551]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  488\n",
      "Training Loss:  [0.06707311]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  489\n",
      "Training Loss:  [0.06683881]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  490\n",
      "Training Loss:  [0.06669511]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  491\n",
      "Training Loss:  [0.06646409]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  492\n",
      "Training Loss:  [0.06623382]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  493\n",
      "Training Loss:  [0.06600577]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  494\n",
      "Training Loss:  [0.06593098]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  495\n",
      "Training Loss:  [0.06561571]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  496\n",
      "Training Loss:  [0.06538501]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  497\n",
      "Training Loss:  [0.06511185]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  498\n",
      "Training Loss:  [0.06520026]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  499\n",
      "Training Loss:  [0.06480146]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  500\n",
      "Training Loss:  [0.06459541]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  501\n",
      "Training Loss:  [0.06432746]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  502\n",
      "Training Loss:  [0.06408181]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  503\n",
      "Training Loss:  [0.06395561]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  504\n",
      "Training Loss:  [0.06372732]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  505\n",
      "Training Loss:  [0.06345131]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  506\n",
      "Training Loss:  [0.06330528]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  507\n",
      "Training Loss:  [0.06307443]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  508\n",
      "Training Loss:  [0.06284497]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  509\n",
      "Training Loss:  [0.06256795]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  510\n",
      "Training Loss:  [0.06251171]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  511\n",
      "Training Loss:  [0.06223861]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  512\n",
      "Training Loss:  [0.06202378]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  513\n",
      "Training Loss:  [0.06174886]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  514\n",
      "Training Loss:  [0.06151975]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  515\n",
      "Training Loss:  [0.06150931]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  516\n",
      "Training Loss:  [0.06109239]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  517\n",
      "Training Loss:  [0.06085282]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  518\n",
      "Training Loss:  [0.06059239]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  519\n",
      "Training Loss:  [0.06048575]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  520\n",
      "Training Loss:  [0.06025252]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  521\n",
      "Training Loss:  [0.05996975]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  522\n",
      "Training Loss:  [0.05975442]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  523\n",
      "Training Loss:  [0.05958224]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  524\n",
      "Training Loss:  [0.05934668]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  525\n",
      "Training Loss:  [0.05906269]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  526\n",
      "Training Loss:  [0.05893219]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  527\n",
      "Training Loss:  [0.05868397]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  528\n",
      "Training Loss:  [0.05845107]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  529\n",
      "Training Loss:  [0.05816714]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  530\n",
      "Training Loss:  [0.05808569]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  531\n",
      "Training Loss:  [0.05783773]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  532\n",
      "Training Loss:  [0.05759099]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  533\n",
      "Training Loss:  [0.0573174]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  534\n",
      "Training Loss:  [0.05701972]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  535\n",
      "Training Loss:  [0.05711162]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  536\n",
      "Training Loss:  [0.05663392]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  537\n",
      "Training Loss:  [0.05639974]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  538\n",
      "Training Loss:  [0.05612252]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  539\n",
      "Training Loss:  [0.05594981]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  540\n",
      "Training Loss:  [0.05568268]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  541\n",
      "Training Loss:  [0.05534998]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  542\n",
      "Training Loss:  [0.05504293]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  543\n",
      "Training Loss:  [0.05483016]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  544\n",
      "Training Loss:  [0.05454313]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  545\n",
      "Training Loss:  [0.05421087]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  546\n",
      "Training Loss:  [0.05397177]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  547\n",
      "Training Loss:  [0.05374818]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  548\n",
      "Training Loss:  [0.05346374]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  549\n",
      "Training Loss:  [0.05313558]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  550\n",
      "Training Loss:  [0.05278483]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  551\n",
      "Training Loss:  [0.05268897]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  552\n",
      "Training Loss:  [0.05228522]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  553\n",
      "Training Loss:  [0.05199621]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  554\n",
      "Training Loss:  [0.05165946]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  555\n",
      "Training Loss:  [0.05154378]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  556\n",
      "Training Loss:  [0.05117748]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  557\n",
      "Training Loss:  [0.05084998]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  558\n",
      "Training Loss:  [0.05052235]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  559\n",
      "Training Loss:  [0.0504146]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  560\n",
      "Training Loss:  [0.05009075]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  561\n",
      "Training Loss:  [0.04978052]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  562\n",
      "Training Loss:  [0.04945919]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  563\n",
      "Training Loss:  [0.04911393]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  564\n",
      "Training Loss:  [0.04905459]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  565\n",
      "Training Loss:  [0.04864053]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  566\n",
      "Training Loss:  [0.04829924]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  567\n",
      "Training Loss:  [0.04797423]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  568\n",
      "Training Loss:  [0.04790529]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  569\n",
      "Training Loss:  [0.04750837]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  570\n",
      "Training Loss:  [0.04716952]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  571\n",
      "Training Loss:  [0.04684616]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  572\n",
      "Training Loss:  [0.04674453]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  573\n",
      "Training Loss:  [0.04637601]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  574\n",
      "Training Loss:  [0.04604313]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  575\n",
      "Training Loss:  [0.04572142]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  576\n",
      "Training Loss:  [0.04558527]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  577\n",
      "Training Loss:  [0.04524655]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  578\n",
      "Training Loss:  [0.04492087]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  579\n",
      "Training Loss:  [0.04460112]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  580\n",
      "Training Loss:  [0.04443034]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  581\n",
      "Training Loss:  [0.04412186]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  582\n",
      "Training Loss:  [0.04381366]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  583\n",
      "Training Loss:  [0.04349902]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  584\n",
      "Training Loss:  [0.04329731]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  585\n",
      "Training Loss:  [0.04296669]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  586\n",
      "Training Loss:  [0.04272622]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  587\n",
      "Training Loss:  [0.04238078]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  588\n",
      "Training Loss:  [0.04215612]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  589\n",
      "Training Loss:  [0.04186161]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  590\n",
      "Training Loss:  [0.04161961]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  591\n",
      "Training Loss:  [0.04128212]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  592\n",
      "Training Loss:  [0.04102878]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  593\n",
      "Training Loss:  [0.04076732]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  594\n",
      "Training Loss:  [0.04052091]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  595\n",
      "Training Loss:  [0.0401939]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  596\n",
      "Training Loss:  [0.0399155]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  597\n",
      "Training Loss:  [0.0396841]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  598\n",
      "Training Loss:  [0.039434]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  599\n",
      "Training Loss:  [0.03911748]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  600\n",
      "Training Loss:  [0.03881821]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  601\n",
      "Training Loss:  [0.0386134]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  602\n",
      "Training Loss:  [0.03836052]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  603\n",
      "Training Loss:  [0.03805432]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  604\n",
      "Training Loss:  [0.03774715]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  605\n",
      "Training Loss:  [0.0377433]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  606\n",
      "Training Loss:  [0.03728783]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  607\n",
      "Training Loss:  [0.03703293]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  608\n",
      "Training Loss:  [0.03674201]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  609\n",
      "Training Loss:  [0.03645776]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  610\n",
      "Training Loss:  [0.03625995]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  611\n",
      "Training Loss:  [0.03600505]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  612\n",
      "Training Loss:  [0.03571571]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  613\n",
      "Training Loss:  [0.03541929]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  614\n",
      "Training Loss:  [0.03523685]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  615\n",
      "Training Loss:  [0.03498928]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  616\n",
      "Training Loss:  [0.03470517]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  617\n",
      "Training Loss:  [0.03440786]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  618\n",
      "Training Loss:  [0.03438873]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  619\n",
      "Training Loss:  [0.03395444]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  620\n",
      "Training Loss:  [0.03370329]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  621\n",
      "Training Loss:  [0.03342112]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  622\n",
      "Training Loss:  [0.03336182]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  623\n",
      "Training Loss:  [0.03302548]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  624\n",
      "Training Loss:  [0.03273253]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  625\n",
      "Training Loss:  [0.03246582]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  626\n",
      "Training Loss:  [0.03237462]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  627\n",
      "Training Loss:  [0.03200789]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  628\n",
      "Training Loss:  [0.03182225]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  629\n",
      "Training Loss:  [0.03151461]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  630\n",
      "Training Loss:  [0.0314057]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  631\n",
      "Training Loss:  [0.0310746]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  632\n",
      "Training Loss:  [0.03089282]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  633\n",
      "Training Loss:  [0.03059359]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  634\n",
      "Training Loss:  [0.03046977]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  635\n",
      "Training Loss:  [0.03016389]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  636\n",
      "Training Loss:  [0.0299851]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  637\n",
      "Training Loss:  [0.02969451]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  638\n",
      "Training Loss:  [0.02956401]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  639\n",
      "Training Loss:  [0.02927525]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  640\n",
      "Training Loss:  [0.02910126]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  641\n",
      "Training Loss:  [0.02881775]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  642\n",
      "Training Loss:  [0.02868735]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  643\n",
      "Training Loss:  [0.02840914]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  644\n",
      "Training Loss:  [0.02824152]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  645\n",
      "Training Loss:  [0.02796586]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  646\n",
      "Training Loss:  [0.02787085]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  647\n",
      "Training Loss:  [0.02762928]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  648\n",
      "Training Loss:  [0.02750555]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  649\n",
      "Training Loss:  [0.02725775]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  650\n",
      "Training Loss:  [0.02717052]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  651\n",
      "Training Loss:  [0.02693155]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  652\n",
      "Training Loss:  [0.02674625]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  653\n",
      "Training Loss:  [0.02660004]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  654\n",
      "Training Loss:  [0.02646434]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  655\n",
      "Training Loss:  [0.02624119]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  656\n",
      "Training Loss:  [0.02605898]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  657\n",
      "Training Loss:  [0.0259124]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  658\n",
      "Training Loss:  [0.02575968]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  659\n",
      "Training Loss:  [0.02555735]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  660\n",
      "Training Loss:  [0.02537673]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  661\n",
      "Training Loss:  [0.02522733]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  662\n",
      "Training Loss:  [0.02506288]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  663\n",
      "Training Loss:  [0.02488089]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  664\n",
      "Training Loss:  [0.02470307]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  665\n",
      "Training Loss:  [0.02455332]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  666\n",
      "Training Loss:  [0.02438401]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  667\n",
      "Training Loss:  [0.02421617]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  668\n",
      "Training Loss:  [0.02404207]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  669\n",
      "Training Loss:  [0.02389498]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  670\n",
      "Training Loss:  [0.02372804]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  671\n",
      "Training Loss:  [0.0235662]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  672\n",
      "Training Loss:  [0.0233964]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  673\n",
      "Training Loss:  [0.02325492]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  674\n",
      "Training Loss:  [0.02309679]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  675\n",
      "Training Loss:  [0.02293281]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  676\n",
      "Training Loss:  [0.02276764]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  677\n",
      "Training Loss:  [0.02263442]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  678\n",
      "Training Loss:  [0.02249034]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  679\n",
      "Training Loss:  [0.02231701]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  680\n",
      "Training Loss:  [0.02215717]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  681\n",
      "Training Loss:  [0.02200178]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  682\n",
      "Training Loss:  [0.0219183]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  683\n",
      "Training Loss:  [0.02172238]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  684\n",
      "Training Loss:  [0.02156953]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  685\n",
      "Training Loss:  [0.02141431]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  686\n",
      "Training Loss:  [0.02136257]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  687\n",
      "Training Loss:  [0.02114294]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  688\n",
      "Training Loss:  [0.02100632]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  689\n",
      "Training Loss:  [0.02084448]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  690\n",
      "Training Loss:  [0.0208271]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  691\n",
      "Training Loss:  [0.02058144]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  692\n",
      "Training Loss:  [0.02046217]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  693\n",
      "Training Loss:  [0.02030267]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  694\n",
      "Training Loss:  [0.02020484]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  695\n",
      "Training Loss:  [0.02006246]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  696\n",
      "Training Loss:  [0.01994788]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  697\n",
      "Training Loss:  [0.01981233]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  698\n",
      "Training Loss:  [0.01967345]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  699\n",
      "Training Loss:  [0.01954675]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  700\n",
      "Training Loss:  [0.01940172]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  701\n",
      "Training Loss:  [0.01935995]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  702\n",
      "Training Loss:  [0.01916066]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  703\n",
      "Training Loss:  [0.01905146]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  704\n",
      "Training Loss:  [0.01890389]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  705\n",
      "Training Loss:  [0.0188153]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  706\n",
      "Training Loss:  [0.0186847]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  707\n",
      "Training Loss:  [0.01858678]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  708\n",
      "Training Loss:  [0.01847591]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  709\n",
      "Training Loss:  [0.01832805]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  710\n",
      "Training Loss:  [0.01822396]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  711\n",
      "Training Loss:  [0.0180793]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  712\n",
      "Training Loss:  [0.01807818]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  713\n",
      "Training Loss:  [0.01785841]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  714\n",
      "Training Loss:  [0.01777561]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  715\n",
      "Training Loss:  [0.01767233]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  716\n",
      "Training Loss:  [0.01754207]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  717\n",
      "Training Loss:  [0.01744329]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  718\n",
      "Training Loss:  [0.01730781]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  719\n",
      "Training Loss:  [0.01729958]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  720\n",
      "Training Loss:  [0.01709921]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  721\n",
      "Training Loss:  [0.01702438]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  722\n",
      "Training Loss:  [0.01692822]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  723\n",
      "Training Loss:  [0.01680022]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  724\n",
      "Training Loss:  [0.01671329]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  725\n",
      "Training Loss:  [0.01657882]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  726\n",
      "Training Loss:  [0.01658665]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  727\n",
      "Training Loss:  [0.01638949]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  728\n",
      "Training Loss:  [0.01628799]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  729\n",
      "Training Loss:  [0.01625035]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  730\n",
      "Training Loss:  [0.01610111]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  731\n",
      "Training Loss:  [0.01602668]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  732\n",
      "Training Loss:  [0.01591768]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  733\n",
      "Training Loss:  [0.01582574]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  734\n",
      "Training Loss:  [0.01574466]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  735\n",
      "Training Loss:  [0.015621]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  736\n",
      "Training Loss:  [0.01562087]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  737\n",
      "Training Loss:  [0.01544953]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  738\n",
      "Training Loss:  [0.01535202]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  739\n",
      "Training Loss:  [0.01532372]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  740\n",
      "Training Loss:  [0.0151793]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  741\n",
      "Training Loss:  [0.01509516]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  742\n",
      "Training Loss:  [0.0150339]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  743\n",
      "Training Loss:  [0.01492639]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  744\n",
      "Training Loss:  [0.01485896]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  745\n",
      "Training Loss:  [0.01475268]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  746\n",
      "Training Loss:  [0.01467725]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  747\n",
      "Training Loss:  [0.01460868]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  748\n",
      "Training Loss:  [0.01449202]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  749\n",
      "Training Loss:  [0.01450129]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  750\n",
      "Training Loss:  [0.01434585]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  751\n",
      "Training Loss:  [0.01424939]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  752\n",
      "Training Loss:  [0.01419673]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  753\n",
      "Training Loss:  [0.01412149]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  754\n",
      "Training Loss:  [0.01402119]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  755\n",
      "Training Loss:  [0.013996]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  756\n",
      "Training Loss:  [0.01387402]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  757\n",
      "Training Loss:  [0.01378887]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  758\n",
      "Training Loss:  [0.01376219]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  759\n",
      "Training Loss:  [0.01364656]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  760\n",
      "Training Loss:  [0.01356657]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  761\n",
      "Training Loss:  [0.01353054]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  762\n",
      "Training Loss:  [0.01342601]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  763\n",
      "Training Loss:  [0.01334945]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  764\n",
      "Training Loss:  [0.01330819]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  765\n",
      "Training Loss:  [0.0132115]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  766\n",
      "Training Loss:  [0.01313713]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  767\n",
      "Training Loss:  [0.01309427]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  768\n",
      "Training Loss:  [0.0130026]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  769\n",
      "Training Loss:  [0.01292942]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  770\n",
      "Training Loss:  [0.01288789]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  771\n",
      "Training Loss:  [0.01279904]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  772\n",
      "Training Loss:  [0.01272621]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  773\n",
      "Training Loss:  [0.01268833]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  774\n",
      "Training Loss:  [0.01260057]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  775\n",
      "Training Loss:  [0.01252739]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  776\n",
      "Training Loss:  [0.01249501]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  777\n",
      "Training Loss:  [0.01240701]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  778\n",
      "Training Loss:  [0.01233288]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  779\n",
      "Training Loss:  [0.01230746]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  780\n",
      "Training Loss:  [0.01221818]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  781\n",
      "Training Loss:  [0.0121426]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  782\n",
      "Training Loss:  [0.01212532]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  783\n",
      "Training Loss:  [0.01203395]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  784\n",
      "Training Loss:  [0.01195648]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  785\n",
      "Training Loss:  [0.01194823]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  786\n",
      "Training Loss:  [0.01185417]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  787\n",
      "Training Loss:  [0.01177637]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  788\n",
      "Training Loss:  [0.01173479]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  789\n",
      "Training Loss:  [0.01167786]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  790\n",
      "Training Loss:  [0.01160432]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  791\n",
      "Training Loss:  [0.0116131]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  792\n",
      "Training Loss:  [0.01149131]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  793\n",
      "Training Loss:  [0.01145765]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  794\n",
      "Training Loss:  [0.01138905]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  795\n",
      "Training Loss:  [0.01133029]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  796\n",
      "Training Loss:  [0.01128966]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  797\n",
      "Training Loss:  [0.0112273]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  798\n",
      "Training Loss:  [0.01116217]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  799\n",
      "Training Loss:  [0.01114091]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  800\n",
      "Training Loss:  [0.01106781]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  801\n",
      "Training Loss:  [0.0109971]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  802\n",
      "Training Loss:  [0.01099583]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  803\n",
      "Training Loss:  [0.01089883]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  804\n",
      "Training Loss:  [0.01085479]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  805\n",
      "Training Loss:  [0.01080267]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  806\n",
      "Training Loss:  [0.0107504]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  807\n",
      "Training Loss:  [0.01070696]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  808\n",
      "Training Loss:  [0.01065484]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  809\n",
      "Training Loss:  [0.0105945]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  810\n",
      "Training Loss:  [0.01057548]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  811\n",
      "Training Loss:  [0.01050884]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  812\n",
      "Training Loss:  [0.01044429]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  813\n",
      "Training Loss:  [0.01041188]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  814\n",
      "Training Loss:  [0.01035981]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  815\n",
      "Training Loss:  [0.01031217]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  816\n",
      "Training Loss:  [0.01026883]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  817\n",
      "Training Loss:  [0.01021225]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  818\n",
      "Training Loss:  [0.010192]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  819\n",
      "Training Loss:  [0.01013152]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  820\n",
      "Training Loss:  [0.01007102]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  821\n",
      "Training Loss:  [0.01004046]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  822\n",
      "Training Loss:  [0.00998955]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  823\n",
      "Training Loss:  [0.00994906]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  824\n",
      "Training Loss:  [0.00990583]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  825\n",
      "Training Loss:  [0.00984954]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  826\n",
      "Training Loss:  [0.00983789]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  827\n",
      "Training Loss:  [0.00976571]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  828\n",
      "Training Loss:  [0.00972876]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  829\n",
      "Training Loss:  [0.0096868]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  830\n",
      "Training Loss:  [0.00963885]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  831\n",
      "Training Loss:  [0.00961274]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  832\n",
      "Training Loss:  [0.00956364]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  833\n",
      "Training Loss:  [0.00950671]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  834\n",
      "Training Loss:  [0.00948154]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  835\n",
      "Training Loss:  [0.00943451]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  836\n",
      "Training Loss:  [0.00940004]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  837\n",
      "Training Loss:  [0.00935949]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  838\n",
      "Training Loss:  [0.00930575]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  839\n",
      "Training Loss:  [0.00930541]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  840\n",
      "Training Loss:  [0.00922862]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  841\n",
      "Training Loss:  [0.00920494]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  842\n",
      "Training Loss:  [0.0091605]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  843\n",
      "Training Loss:  [0.00911187]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  844\n",
      "Training Loss:  [0.0091027]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  845\n",
      "Training Loss:  [0.00903747]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  846\n",
      "Training Loss:  [0.00900971]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  847\n",
      "Training Loss:  [0.00897028]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  848\n",
      "Training Loss:  [0.00892439]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  849\n",
      "Training Loss:  [0.0089123]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  850\n",
      "Training Loss:  [0.00885226]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  851\n",
      "Training Loss:  [0.00882455]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  852\n",
      "Training Loss:  [0.00878712]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  853\n",
      "Training Loss:  [0.00874259]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  854\n",
      "Training Loss:  [0.00873225]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  855\n",
      "Training Loss:  [0.00867263]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  856\n",
      "Training Loss:  [0.00864785]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  857\n",
      "Training Loss:  [0.00861039]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  858\n",
      "Training Loss:  [0.00856624]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  859\n",
      "Training Loss:  [0.00856087]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  860\n",
      "Training Loss:  [0.00849838]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  861\n",
      "Training Loss:  [0.0084785]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  862\n",
      "Training Loss:  [0.00843966]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  863\n",
      "Training Loss:  [0.00839517]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  864\n",
      "Training Loss:  [0.00839702]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  865\n",
      "Training Loss:  [0.00833078]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  866\n",
      "Training Loss:  [0.00830994]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  867\n",
      "Training Loss:  [0.00828167]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  868\n",
      "Training Loss:  [0.00823131]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  869\n",
      "Training Loss:  [0.00824025]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  870\n",
      "Training Loss:  [0.00817488]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  871\n",
      "Training Loss:  [0.00814623]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  872\n",
      "Training Loss:  [0.00812204]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  873\n",
      "Training Loss:  [0.00807601]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  874\n",
      "Training Loss:  [0.00805211]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  875\n",
      "Training Loss:  [0.00801467]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  876\n",
      "Training Loss:  [0.00800898]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  877\n",
      "Training Loss:  [0.00795289]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  878\n",
      "Training Loss:  [0.00793293]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  879\n",
      "Training Loss:  [0.007907]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  880\n",
      "Training Loss:  [0.00785958]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  881\n",
      "Training Loss:  [0.00787309]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  882\n",
      "Training Loss:  [0.00781217]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  883\n",
      "Training Loss:  [0.00778084]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  884\n",
      "Training Loss:  [0.00775065]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  885\n",
      "Training Loss:  [0.00772321]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  886\n",
      "Training Loss:  [0.00769615]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  887\n",
      "Training Loss:  [0.00765841]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  888\n",
      "Training Loss:  [0.00764054]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  889\n",
      "Training Loss:  [0.00760398]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  890\n",
      "Training Loss:  [0.00759504]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  891\n",
      "Training Loss:  [0.00754746]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  892\n",
      "Training Loss:  [0.00753294]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  893\n",
      "Training Loss:  [0.00750002]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  894\n",
      "Training Loss:  [0.00746575]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  895\n",
      "Training Loss:  [0.00744733]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  896\n",
      "Training Loss:  [0.00741162]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  897\n",
      "Training Loss:  [0.00740615]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  898\n",
      "Training Loss:  [0.0073573]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  899\n",
      "Training Loss:  [0.00734096]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  900\n",
      "Training Loss:  [0.00731872]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  901\n",
      "Training Loss:  [0.00727907]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  902\n",
      "Training Loss:  [0.00726055]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  903\n",
      "Training Loss:  [0.00722858]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  904\n",
      "Training Loss:  [0.00722873]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  905\n",
      "Training Loss:  [0.00718203]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  906\n",
      "Training Loss:  [0.00715838]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  907\n",
      "Training Loss:  [0.00713954]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  908\n",
      "Training Loss:  [0.0071098]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  909\n",
      "Training Loss:  [0.00708092]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  910\n",
      "Training Loss:  [0.00705561]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  911\n",
      "Training Loss:  [0.00703471]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  912\n",
      "Training Loss:  [0.00700318]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  913\n",
      "Training Loss:  [0.00700388]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  914\n",
      "Training Loss:  [0.00695902]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  915\n",
      "Training Loss:  [0.00693802]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  916\n",
      "Training Loss:  [0.00691995]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  917\n",
      "Training Loss:  [0.0068921]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  918\n",
      "Training Loss:  [0.00686427]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  919\n",
      "Training Loss:  [0.00684151]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  920\n",
      "Training Loss:  [0.00682078]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  921\n",
      "Training Loss:  [0.00679015]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  922\n",
      "Training Loss:  [0.00679425]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  923\n",
      "Training Loss:  [0.00675118]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  924\n",
      "Training Loss:  [0.00672864]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  925\n",
      "Training Loss:  [0.00670446]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  926\n",
      "Training Loss:  [0.00668698]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  927\n",
      "Training Loss:  [0.00666304]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  928\n",
      "Training Loss:  [0.00664189]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  929\n",
      "Training Loss:  [0.00661581]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  930\n",
      "Training Loss:  [0.00659249]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  931\n",
      "Training Loss:  [0.00657451]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  932\n",
      "Training Loss:  [0.00654624]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  933\n",
      "Training Loss:  [0.00654873]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  934\n",
      "Training Loss:  [0.0065092]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  935\n",
      "Training Loss:  [0.00648839]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  936\n",
      "Training Loss:  [0.00646521]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  937\n",
      "Training Loss:  [0.00645012]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  938\n",
      "Training Loss:  [0.00642686]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  939\n",
      "Training Loss:  [0.00640957]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  940\n",
      "Training Loss:  [0.00638135]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  941\n",
      "Training Loss:  [0.0063627]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  942\n",
      "Training Loss:  [0.00634379]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  943\n",
      "Training Loss:  [0.00631693]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  944\n",
      "Training Loss:  [0.0063048]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  945\n",
      "Training Loss:  [0.0062772]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  946\n",
      "Training Loss:  [0.00627881]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  947\n",
      "Training Loss:  [0.00624268]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  948\n",
      "Training Loss:  [0.00622353]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  949\n",
      "Training Loss:  [0.00620136]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  950\n",
      "Training Loss:  [0.00618895]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  951\n",
      "Training Loss:  [0.00616634]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  952\n",
      "Training Loss:  [0.00615315]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  953\n",
      "Training Loss:  [0.00612272]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  954\n",
      "Training Loss:  [0.00610895]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  955\n",
      "Training Loss:  [0.00608913]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  956\n",
      "Training Loss:  [0.00606762]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  957\n",
      "Training Loss:  [0.00605019]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  958\n",
      "Training Loss:  [0.00602843]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  959\n",
      "Training Loss:  [0.0060144]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  960\n",
      "Training Loss:  [0.00598967]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  961\n",
      "Training Loss:  [0.00599409]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  962\n",
      "Training Loss:  [0.00596041]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  963\n",
      "Training Loss:  [0.00594102]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  964\n",
      "Training Loss:  [0.00591897]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  965\n",
      "Training Loss:  [0.00591338]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  966\n",
      "Training Loss:  [0.00588351]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  967\n",
      "Training Loss:  [0.00586937]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  968\n",
      "Training Loss:  [0.00585018]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  969\n",
      "Training Loss:  [0.00583684]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  970\n",
      "Training Loss:  [0.0058179]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  971\n",
      "Training Loss:  [0.00580583]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  972\n",
      "Training Loss:  [0.00577834]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  973\n",
      "Training Loss:  [0.00576691]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  974\n",
      "Training Loss:  [0.00574843]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  975\n",
      "Training Loss:  [0.00573165]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  976\n",
      "Training Loss:  [0.005712]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  977\n",
      "Training Loss:  [0.00569587]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  978\n",
      "Training Loss:  [0.00568097]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  979\n",
      "Training Loss:  [0.00566035]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  980\n",
      "Training Loss:  [0.00564688]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  981\n",
      "Training Loss:  [0.00562742]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  982\n",
      "Training Loss:  [0.00561512]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  983\n",
      "Training Loss:  [0.00559288]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  984\n",
      "Training Loss:  [0.00558386]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  985\n",
      "Training Loss:  [0.0055607]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  986\n",
      "Training Loss:  [0.00556576]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  987\n",
      "Training Loss:  [0.0055364]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  988\n",
      "Training Loss:  [0.00551848]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  989\n",
      "Training Loss:  [0.00549778]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  990\n",
      "Training Loss:  [0.00549811]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  991\n",
      "Training Loss:  [0.00547083]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  992\n",
      "Training Loss:  [0.00545558]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  993\n",
      "Training Loss:  [0.0054364]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  994\n",
      "Training Loss:  [0.00543283]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  995\n",
      "Training Loss:  [0.00540741]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  996\n",
      "Training Loss:  [0.00539416]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  997\n",
      "Training Loss:  [0.00537611]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  998\n",
      "Training Loss:  [0.00537]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  999\n",
      "Training Loss:  [0.00534599]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(X_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 0, 0] [0]\n",
      "Training Loss:  [0.00534599]\n",
      "Training Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train), model.predict(np.array([[1,1,0]])))\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Desccent Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Training Loss:  [0.14291094]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  1\n",
      "Training Loss:  [0.14252709]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  2\n",
      "Training Loss:  [0.14218063]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  3\n",
      "Training Loss:  [0.14187051]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  4\n",
      "Training Loss:  [0.14159583]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  5\n",
      "Training Loss:  [0.14135586]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  6\n",
      "Training Loss:  [0.14114996]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  7\n",
      "Training Loss:  [0.14097761]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  8\n",
      "Training Loss:  [0.14083839]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  9\n",
      "Training Loss:  [0.14073194]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  10\n",
      "Training Loss:  [0.14065794]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  11\n",
      "Training Loss:  [0.14061611]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  12\n",
      "Training Loss:  [0.14060618]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  13\n",
      "Training Loss:  [0.14062784]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  14\n",
      "Training Loss:  [0.1402834]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  15\n",
      "Training Loss:  [0.13838453]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  16\n",
      "Training Loss:  [0.13679629]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  17\n",
      "Training Loss:  [0.13505821]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  18\n",
      "Training Loss:  [0.13349579]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  19\n",
      "Training Loss:  [0.13204644]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  20\n",
      "Training Loss:  [0.13154127]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  21\n",
      "Training Loss:  [0.131293]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  22\n",
      "Training Loss:  [0.13084111]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  23\n",
      "Training Loss:  [0.13051102]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  24\n",
      "Training Loss:  [0.130245]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  25\n",
      "Training Loss:  [0.12987408]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  26\n",
      "Training Loss:  [0.12976103]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  27\n",
      "Training Loss:  [0.12947576]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  28\n",
      "Training Loss:  [0.12958617]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  29\n",
      "Training Loss:  [0.12965795]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  30\n",
      "Training Loss:  [0.12968843]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  31\n",
      "Training Loss:  [0.12993396]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  32\n",
      "Training Loss:  [0.12999147]\n",
      "Training Accuracy:  0.2857142857142857\n",
      "\n",
      "Epoch  33\n",
      "Training Loss:  [0.13019378]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  34\n",
      "Training Loss:  [0.13015836]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  35\n",
      "Training Loss:  [0.1302621]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  36\n",
      "Training Loss:  [0.1303471]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  37\n",
      "Training Loss:  [0.13068631]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  38\n",
      "Training Loss:  [0.13089198]\n",
      "Training Accuracy:  0.42857142857142855\n",
      "\n",
      "Epoch  39\n",
      "Training Loss:  [0.13089177]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  40\n",
      "Training Loss:  [0.13112769]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  41\n",
      "Training Loss:  [0.13142106]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  42\n",
      "Training Loss:  [0.13161353]\n",
      "Training Accuracy:  0.5714285714285714\n",
      "\n",
      "Epoch  43\n",
      "Training Loss:  [0.13168321]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  44\n",
      "Training Loss:  [0.13204862]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  45\n",
      "Training Loss:  [0.13221645]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  46\n",
      "Training Loss:  [0.13223554]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  47\n",
      "Training Loss:  [0.13272602]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  48\n",
      "Training Loss:  [0.13274968]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  49\n",
      "Training Loss:  [0.13291736]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  50\n",
      "Training Loss:  [0.13272923]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  51\n",
      "Training Loss:  [0.13315498]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  52\n",
      "Training Loss:  [0.13283234]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  53\n",
      "Training Loss:  [0.13306147]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  54\n",
      "Training Loss:  [0.13294188]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  55\n",
      "Training Loss:  [0.13293249]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  56\n",
      "Training Loss:  [0.13292392]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  57\n",
      "Training Loss:  [0.13270492]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  58\n",
      "Training Loss:  [0.13287094]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  59\n",
      "Training Loss:  [0.13287276]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  60\n",
      "Training Loss:  [0.13266986]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  61\n",
      "Training Loss:  [0.13285821]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  62\n",
      "Training Loss:  [0.13279532]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  63\n",
      "Training Loss:  [0.1326484]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  64\n",
      "Training Loss:  [0.13281233]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  65\n",
      "Training Loss:  [0.13250656]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  66\n",
      "Training Loss:  [0.13270117]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  67\n",
      "Training Loss:  [0.13267758]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  68\n",
      "Training Loss:  [0.13247463]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  69\n",
      "Training Loss:  [0.1327342]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  70\n",
      "Training Loss:  [0.13241267]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  71\n",
      "Training Loss:  [0.13253226]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  72\n",
      "Training Loss:  [0.13258346]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  73\n",
      "Training Loss:  [0.13234572]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  74\n",
      "Training Loss:  [0.13256407]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  75\n",
      "Training Loss:  [0.1323459]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  76\n",
      "Training Loss:  [0.13232464]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  77\n",
      "Training Loss:  [0.13239397]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  78\n",
      "Training Loss:  [0.13221122]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  79\n",
      "Training Loss:  [0.13235198]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  80\n",
      "Training Loss:  [0.13243937]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  81\n",
      "Training Loss:  [0.1321196]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  82\n",
      "Training Loss:  [0.13206713]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  83\n",
      "Training Loss:  [0.13110946]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  84\n",
      "Training Loss:  [0.13095371]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  85\n",
      "Training Loss:  [0.12997715]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  86\n",
      "Training Loss:  [0.12876932]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  87\n",
      "Training Loss:  [0.12870079]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  88\n",
      "Training Loss:  [0.12775214]\n",
      "Training Accuracy:  0.7142857142857143\n",
      "\n",
      "Epoch  89\n",
      "Training Loss:  [0.12665253]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  90\n",
      "Training Loss:  [0.12624657]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  91\n",
      "Training Loss:  [0.12557625]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  92\n",
      "Training Loss:  [0.12496916]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  93\n",
      "Training Loss:  [0.12420574]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  94\n",
      "Training Loss:  [0.12403834]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  95\n",
      "Training Loss:  [0.1227378]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  96\n",
      "Training Loss:  [0.12221191]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  97\n",
      "Training Loss:  [0.1221365]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  98\n",
      "Training Loss:  [0.12077104]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  99\n",
      "Training Loss:  [0.12027647]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  100\n",
      "Training Loss:  [0.1201989]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  101\n",
      "Training Loss:  [0.11912325]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  102\n",
      "Training Loss:  [0.11834564]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  103\n",
      "Training Loss:  [0.11789376]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  104\n",
      "Training Loss:  [0.11733582]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  105\n",
      "Training Loss:  [0.11666417]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  106\n",
      "Training Loss:  [0.11584386]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  107\n",
      "Training Loss:  [0.11575497]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  108\n",
      "Training Loss:  [0.11519613]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  109\n",
      "Training Loss:  [0.11416271]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  110\n",
      "Training Loss:  [0.11382917]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  111\n",
      "Training Loss:  [0.11321108]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  112\n",
      "Training Loss:  [0.11331625]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  113\n",
      "Training Loss:  [0.11183025]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  114\n",
      "Training Loss:  [0.11161424]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  115\n",
      "Training Loss:  [0.11165439]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  116\n",
      "Training Loss:  [0.11084118]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  117\n",
      "Training Loss:  [0.11090322]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  118\n",
      "Training Loss:  [0.10978968]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  119\n",
      "Training Loss:  [0.11008617]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  120\n",
      "Training Loss:  [0.10938976]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  121\n",
      "Training Loss:  [0.10937216]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  122\n",
      "Training Loss:  [0.10894218]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  123\n",
      "Training Loss:  [0.10816162]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  124\n",
      "Training Loss:  [0.10779944]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  125\n",
      "Training Loss:  [0.1076223]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  126\n",
      "Training Loss:  [0.10734941]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  127\n",
      "Training Loss:  [0.10708511]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  128\n",
      "Training Loss:  [0.10619457]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  129\n",
      "Training Loss:  [0.10603363]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  130\n",
      "Training Loss:  [0.10594368]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  131\n",
      "Training Loss:  [0.10526651]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  132\n",
      "Training Loss:  [0.10509771]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  133\n",
      "Training Loss:  [0.10483424]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  134\n",
      "Training Loss:  [0.10394961]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  135\n",
      "Training Loss:  [0.103768]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  136\n",
      "Training Loss:  [0.10357568]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  137\n",
      "Training Loss:  [0.10321594]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  138\n",
      "Training Loss:  [0.10301274]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  139\n",
      "Training Loss:  [0.10258977]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  140\n",
      "Training Loss:  [0.10235459]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  141\n",
      "Training Loss:  [0.10194056]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  142\n",
      "Training Loss:  [0.10169806]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  143\n",
      "Training Loss:  [0.10136758]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  144\n",
      "Training Loss:  [0.10086322]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  145\n",
      "Training Loss:  [0.10011604]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  146\n",
      "Training Loss:  [0.09991749]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  147\n",
      "Training Loss:  [0.09972737]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  148\n",
      "Training Loss:  [0.09946711]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  149\n",
      "Training Loss:  [0.0990821]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  150\n",
      "Training Loss:  [0.09887778]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  151\n",
      "Training Loss:  [0.09837033]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  152\n",
      "Training Loss:  [0.09841889]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  153\n",
      "Training Loss:  [0.09762159]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  154\n",
      "Training Loss:  [0.09743804]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  155\n",
      "Training Loss:  [0.09686899]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  156\n",
      "Training Loss:  [0.09683073]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  157\n",
      "Training Loss:  [0.09628488]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  158\n",
      "Training Loss:  [0.09603667]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  159\n",
      "Training Loss:  [0.0954582]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  160\n",
      "Training Loss:  [0.09545273]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  161\n",
      "Training Loss:  [0.09479035]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  162\n",
      "Training Loss:  [0.09487163]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  163\n",
      "Training Loss:  [0.09421747]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  164\n",
      "Training Loss:  [0.09413847]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  165\n",
      "Training Loss:  [0.09318676]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  166\n",
      "Training Loss:  [0.09325381]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  167\n",
      "Training Loss:  [0.09302889]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  168\n",
      "Training Loss:  [0.09270523]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  169\n",
      "Training Loss:  [0.09247266]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  170\n",
      "Training Loss:  [0.09181459]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  171\n",
      "Training Loss:  [0.09162838]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  172\n",
      "Training Loss:  [0.09140127]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  173\n",
      "Training Loss:  [0.09094916]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  174\n",
      "Training Loss:  [0.09066289]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  175\n",
      "Training Loss:  [0.0903923]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  176\n",
      "Training Loss:  [0.09007069]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  177\n",
      "Training Loss:  [0.08986371]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  178\n",
      "Training Loss:  [0.08908232]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  179\n",
      "Training Loss:  [0.08908583]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  180\n",
      "Training Loss:  [0.0888751]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  181\n",
      "Training Loss:  [0.08838906]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  182\n",
      "Training Loss:  [0.08811724]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  183\n",
      "Training Loss:  [0.08788875]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  184\n",
      "Training Loss:  [0.08762458]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  185\n",
      "Training Loss:  [0.08738221]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  186\n",
      "Training Loss:  [0.08677476]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  187\n",
      "Training Loss:  [0.08658952]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  188\n",
      "Training Loss:  [0.08628452]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  189\n",
      "Training Loss:  [0.08583657]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  190\n",
      "Training Loss:  [0.08565115]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  191\n",
      "Training Loss:  [0.08534766]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  192\n",
      "Training Loss:  [0.08478885]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  193\n",
      "Training Loss:  [0.08471536]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  194\n",
      "Training Loss:  [0.0844188]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  195\n",
      "Training Loss:  [0.08395842]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  196\n",
      "Training Loss:  [0.08367521]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  197\n",
      "Training Loss:  [0.08349561]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  198\n",
      "Training Loss:  [0.08296186]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  199\n",
      "Training Loss:  [0.08277742]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  200\n",
      "Training Loss:  [0.08250423]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  201\n",
      "Training Loss:  [0.0821708]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  202\n",
      "Training Loss:  [0.08207033]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  203\n",
      "Training Loss:  [0.0815447]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  204\n",
      "Training Loss:  [0.08134771]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  205\n",
      "Training Loss:  [0.08091968]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  206\n",
      "Training Loss:  [0.08071786]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  207\n",
      "Training Loss:  [0.08043216]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  208\n",
      "Training Loss:  [0.08000619]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  209\n",
      "Training Loss:  [0.07972961]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  210\n",
      "Training Loss:  [0.07951779]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  211\n",
      "Training Loss:  [0.07902569]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  212\n",
      "Training Loss:  [0.0789056]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  213\n",
      "Training Loss:  [0.07840537]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  214\n",
      "Training Loss:  [0.07827942]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  215\n",
      "Training Loss:  [0.07778819]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  216\n",
      "Training Loss:  [0.07765328]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  217\n",
      "Training Loss:  [0.07722178]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  218\n",
      "Training Loss:  [0.0770305]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  219\n",
      "Training Loss:  [0.0765677]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  220\n",
      "Training Loss:  [0.0764063]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  221\n",
      "Training Loss:  [0.07613248]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  222\n",
      "Training Loss:  [0.07569867]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  223\n",
      "Training Loss:  [0.07545825]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  224\n",
      "Training Loss:  [0.07499534]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  225\n",
      "Training Loss:  [0.07483606]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  226\n",
      "Training Loss:  [0.07440132]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  227\n",
      "Training Loss:  [0.07412997]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  228\n",
      "Training Loss:  [0.07370357]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  229\n",
      "Training Loss:  [0.07350525]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  230\n",
      "Training Loss:  [0.0730741]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  231\n",
      "Training Loss:  [0.07282654]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  232\n",
      "Training Loss:  [0.07239702]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  233\n",
      "Training Loss:  [0.07219667]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  234\n",
      "Training Loss:  [0.07176401]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  235\n",
      "Training Loss:  [0.07150635]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  236\n",
      "Training Loss:  [0.07105886]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  237\n",
      "Training Loss:  [0.07087333]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  238\n",
      "Training Loss:  [0.07043557]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  239\n",
      "Training Loss:  [0.07004131]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  240\n",
      "Training Loss:  [0.06980505]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  241\n",
      "Training Loss:  [0.06951752]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  242\n",
      "Training Loss:  [0.06909477]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  243\n",
      "Training Loss:  [0.06865019]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  244\n",
      "Training Loss:  [0.06843673]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  245\n",
      "Training Loss:  [0.0679976]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  246\n",
      "Training Loss:  [0.06777597]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  247\n",
      "Training Loss:  [0.06733314]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  248\n",
      "Training Loss:  [0.06694122]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  249\n",
      "Training Loss:  [0.06665736]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  250\n",
      "Training Loss:  [0.06636468]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  251\n",
      "Training Loss:  [0.06591561]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  252\n",
      "Training Loss:  [0.06547357]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  253\n",
      "Training Loss:  [0.06517335]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  254\n",
      "Training Loss:  [0.06472251]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  255\n",
      "Training Loss:  [0.06441751]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  256\n",
      "Training Loss:  [0.06396849]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  257\n",
      "Training Loss:  [0.06352333]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  258\n",
      "Training Loss:  [0.06326343]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  259\n",
      "Training Loss:  [0.06281251]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  260\n",
      "Training Loss:  [0.06254425]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  261\n",
      "Training Loss:  [0.06208817]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  262\n",
      "Training Loss:  [0.06162608]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  263\n",
      "Training Loss:  [0.06130392]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  264\n",
      "Training Loss:  [0.06083995]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  265\n",
      "Training Loss:  [0.06050946]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  266\n",
      "Training Loss:  [0.06004503]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  267\n",
      "Training Loss:  [0.05958729]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  268\n",
      "Training Loss:  [0.05929887]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  269\n",
      "Training Loss:  [0.05883149]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  270\n",
      "Training Loss:  [0.05838421]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  271\n",
      "Training Loss:  [0.05807006]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  272\n",
      "Training Loss:  [0.05759884]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  273\n",
      "Training Loss:  [0.05712786]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  274\n",
      "Training Loss:  [0.05683191]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  275\n",
      "Training Loss:  [0.05635043]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  276\n",
      "Training Loss:  [0.05600319]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  277\n",
      "Training Loss:  [0.05551976]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  278\n",
      "Training Loss:  [0.05505415]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  279\n",
      "Training Loss:  [0.05458252]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  280\n",
      "Training Loss:  [0.05426927]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  281\n",
      "Training Loss:  [0.05379352]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  282\n",
      "Training Loss:  [0.05342915]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  283\n",
      "Training Loss:  [0.05296873]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  284\n",
      "Training Loss:  [0.05248639]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  285\n",
      "Training Loss:  [0.05202997]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  286\n",
      "Training Loss:  [0.05169837]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  287\n",
      "Training Loss:  [0.05123822]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  288\n",
      "Training Loss:  [0.05086245]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  289\n",
      "Training Loss:  [0.05040789]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  290\n",
      "Training Loss:  [0.04994197]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  291\n",
      "Training Loss:  [0.04946972]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  292\n",
      "Training Loss:  [0.04916404]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  293\n",
      "Training Loss:  [0.04869365]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  294\n",
      "Training Loss:  [0.04827096]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  295\n",
      "Training Loss:  [0.04793231]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  296\n",
      "Training Loss:  [0.04747731]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  297\n",
      "Training Loss:  [0.04702714]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  298\n",
      "Training Loss:  [0.04661437]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  299\n",
      "Training Loss:  [0.0462343]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  300\n",
      "Training Loss:  [0.04579369]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  301\n",
      "Training Loss:  [0.04544364]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  302\n",
      "Training Loss:  [0.04501658]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  303\n",
      "Training Loss:  [0.04458153]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  304\n",
      "Training Loss:  [0.04415905]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  305\n",
      "Training Loss:  [0.04386073]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  306\n",
      "Training Loss:  [0.043442]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  307\n",
      "Training Loss:  [0.04302306]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  308\n",
      "Training Loss:  [0.04270077]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  309\n",
      "Training Loss:  [0.04229116]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  310\n",
      "Training Loss:  [0.04188564]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  311\n",
      "Training Loss:  [0.04148455]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  312\n",
      "Training Loss:  [0.04121197]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  313\n",
      "Training Loss:  [0.04082855]\n",
      "Training Accuracy:  0.8571428571428571\n",
      "\n",
      "Epoch  314\n",
      "Training Loss:  [0.04041497]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  315\n",
      "Training Loss:  [0.04011331]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  316\n",
      "Training Loss:  [0.03973004]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  317\n",
      "Training Loss:  [0.03934022]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  318\n",
      "Training Loss:  [0.03897607]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  319\n",
      "Training Loss:  [0.03871939]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  320\n",
      "Training Loss:  [0.03834958]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  321\n",
      "Training Loss:  [0.03798745]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  322\n",
      "Training Loss:  [0.03770087]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  323\n",
      "Training Loss:  [0.03734141]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  324\n",
      "Training Loss:  [0.03701184]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  325\n",
      "Training Loss:  [0.03664929]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  326\n",
      "Training Loss:  [0.03632767]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  327\n",
      "Training Loss:  [0.03607851]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  328\n",
      "Training Loss:  [0.03573274]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  329\n",
      "Training Loss:  [0.03544033]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  330\n",
      "Training Loss:  [0.03519397]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  331\n",
      "Training Loss:  [0.03491076]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  332\n",
      "Training Loss:  [0.03455394]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  333\n",
      "Training Loss:  [0.03426395]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  334\n",
      "Training Loss:  [0.03404564]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  335\n",
      "Training Loss:  [0.03375903]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  336\n",
      "Training Loss:  [0.0333928]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  337\n",
      "Training Loss:  [0.03319468]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  338\n",
      "Training Loss:  [0.03286279]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  339\n",
      "Training Loss:  [0.03257331]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  340\n",
      "Training Loss:  [0.03227062]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  341\n",
      "Training Loss:  [0.03201248]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  342\n",
      "Training Loss:  [0.03184813]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  343\n",
      "Training Loss:  [0.03153949]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  344\n",
      "Training Loss:  [0.03127984]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  345\n",
      "Training Loss:  [0.03114221]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  346\n",
      "Training Loss:  [0.0307908]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  347\n",
      "Training Loss:  [0.03054568]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  348\n",
      "Training Loss:  [0.03030352]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  349\n",
      "Training Loss:  [0.03010628]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  350\n",
      "Training Loss:  [0.02995195]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  351\n",
      "Training Loss:  [0.02962216]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  352\n",
      "Training Loss:  [0.02944076]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  353\n",
      "Training Loss:  [0.02916633]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  354\n",
      "Training Loss:  [0.02893202]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  355\n",
      "Training Loss:  [0.02870865]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  356\n",
      "Training Loss:  [0.02848346]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  357\n",
      "Training Loss:  [0.0283501]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  358\n",
      "Training Loss:  [0.02813513]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  359\n",
      "Training Loss:  [0.02791455]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  360\n",
      "Training Loss:  [0.02773752]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  361\n",
      "Training Loss:  [0.02754861]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  362\n",
      "Training Loss:  [0.02726939]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  363\n",
      "Training Loss:  [0.02706143]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  364\n",
      "Training Loss:  [0.02685627]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  365\n",
      "Training Loss:  [0.02673441]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  366\n",
      "Training Loss:  [0.02653075]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  367\n",
      "Training Loss:  [0.02632851]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  368\n",
      "Training Loss:  [0.02614217]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  369\n",
      "Training Loss:  [0.02598711]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  370\n",
      "Training Loss:  [0.02578946]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  371\n",
      "Training Loss:  [0.02559294]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  372\n",
      "Training Loss:  [0.02539832]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  373\n",
      "Training Loss:  [0.02528386]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  374\n",
      "Training Loss:  [0.02509107]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  375\n",
      "Training Loss:  [0.0249002]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  376\n",
      "Training Loss:  [0.024765]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  377\n",
      "Training Loss:  [0.0245789]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  378\n",
      "Training Loss:  [0.02449255]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  379\n",
      "Training Loss:  [0.02426727]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  380\n",
      "Training Loss:  [0.02404081]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  381\n",
      "Training Loss:  [0.02401232]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  382\n",
      "Training Loss:  [0.0238176]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  383\n",
      "Training Loss:  [0.02364317]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  384\n",
      "Training Loss:  [0.02352849]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  385\n",
      "Training Loss:  [0.02336334]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  386\n",
      "Training Loss:  [0.02319705]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  387\n",
      "Training Loss:  [0.02308101]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  388\n",
      "Training Loss:  [0.02290478]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  389\n",
      "Training Loss:  [0.02291363]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  390\n",
      "Training Loss:  [0.02262891]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  391\n",
      "Training Loss:  [0.02247813]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  392\n",
      "Training Loss:  [0.02238527]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  393\n",
      "Training Loss:  [0.02219725]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  394\n",
      "Training Loss:  [0.02210408]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  395\n",
      "Training Loss:  [0.02193015]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  396\n",
      "Training Loss:  [0.02182163]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  397\n",
      "Training Loss:  [0.02167594]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  398\n",
      "Training Loss:  [0.02157834]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  399\n",
      "Training Loss:  [0.0214142]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  400\n",
      "Training Loss:  [0.02134893]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  401\n",
      "Training Loss:  [0.02118155]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  402\n",
      "Training Loss:  [0.02106793]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  403\n",
      "Training Loss:  [0.02090098]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  404\n",
      "Training Loss:  [0.0208445]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  405\n",
      "Training Loss:  [0.02069353]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  406\n",
      "Training Loss:  [0.02056362]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  407\n",
      "Training Loss:  [0.02047337]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  408\n",
      "Training Loss:  [0.0203405]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  409\n",
      "Training Loss:  [0.02022845]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  410\n",
      "Training Loss:  [0.02007867]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  411\n",
      "Training Loss:  [0.01998656]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  412\n",
      "Training Loss:  [0.01989961]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  413\n",
      "Training Loss:  [0.01978049]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  414\n",
      "Training Loss:  [0.01967902]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  415\n",
      "Training Loss:  [0.01957117]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  416\n",
      "Training Loss:  [0.01947803]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  417\n",
      "Training Loss:  [0.01933971]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  418\n",
      "Training Loss:  [0.01922142]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  419\n",
      "Training Loss:  [0.01910867]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  420\n",
      "Training Loss:  [0.01906831]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  421\n",
      "Training Loss:  [0.01901843]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  422\n",
      "Training Loss:  [0.0188013]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  423\n",
      "Training Loss:  [0.01877312]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  424\n",
      "Training Loss:  [0.01863578]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  425\n",
      "Training Loss:  [0.01852415]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  426\n",
      "Training Loss:  [0.01842789]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  427\n",
      "Training Loss:  [0.01834465]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  428\n",
      "Training Loss:  [0.01826971]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  429\n",
      "Training Loss:  [0.01815503]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  430\n",
      "Training Loss:  [0.01802119]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  431\n",
      "Training Loss:  [0.0179644]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  432\n",
      "Training Loss:  [0.01787646]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  433\n",
      "Training Loss:  [0.01775011]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  434\n",
      "Training Loss:  [0.01769062]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  435\n",
      "Training Loss:  [0.01761056]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  436\n",
      "Training Loss:  [0.01752322]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  437\n",
      "Training Loss:  [0.01741376]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  438\n",
      "Training Loss:  [0.01734359]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  439\n",
      "Training Loss:  [0.01728291]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  440\n",
      "Training Loss:  [0.01717279]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  441\n",
      "Training Loss:  [0.01709439]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  442\n",
      "Training Loss:  [0.01698587]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  443\n",
      "Training Loss:  [0.01692433]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  444\n",
      "Training Loss:  [0.01685035]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  445\n",
      "Training Loss:  [0.01675361]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  446\n",
      "Training Loss:  [0.01672379]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  447\n",
      "Training Loss:  [0.01659109]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  448\n",
      "Training Loss:  [0.01651318]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  449\n",
      "Training Loss:  [0.01642404]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  450\n",
      "Training Loss:  [0.0163444]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  451\n",
      "Training Loss:  [0.01630902]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  452\n",
      "Training Loss:  [0.01618533]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  453\n",
      "Training Loss:  [0.0161634]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  454\n",
      "Training Loss:  [0.01608571]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  455\n",
      "Training Loss:  [0.01592895]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  456\n",
      "Training Loss:  [0.01589458]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  457\n",
      "Training Loss:  [0.0157945]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  458\n",
      "Training Loss:  [0.0157754]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  459\n",
      "Training Loss:  [0.01568123]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  460\n",
      "Training Loss:  [0.01562549]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  461\n",
      "Training Loss:  [0.01554833]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  462\n",
      "Training Loss:  [0.01548252]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  463\n",
      "Training Loss:  [0.01541452]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  464\n",
      "Training Loss:  [0.01528659]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  465\n",
      "Training Loss:  [0.01528515]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  466\n",
      "Training Loss:  [0.01519622]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  467\n",
      "Training Loss:  [0.01512237]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  468\n",
      "Training Loss:  [0.0150254]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  469\n",
      "Training Loss:  [0.01501998]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  470\n",
      "Training Loss:  [0.01492317]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  471\n",
      "Training Loss:  [0.01485677]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  472\n",
      "Training Loss:  [0.01479178]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  473\n",
      "Training Loss:  [0.01478871]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  474\n",
      "Training Loss:  [0.01466711]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  475\n",
      "Training Loss:  [0.01462533]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  476\n",
      "Training Loss:  [0.0145954]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  477\n",
      "Training Loss:  [0.0144582]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  478\n",
      "Training Loss:  [0.01441964]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  479\n",
      "Training Loss:  [0.01433845]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  480\n",
      "Training Loss:  [0.01430736]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  481\n",
      "Training Loss:  [0.01420041]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  482\n",
      "Training Loss:  [0.01417235]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  483\n",
      "Training Loss:  [0.0141011]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  484\n",
      "Training Loss:  [0.01407755]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  485\n",
      "Training Loss:  [0.01396904]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  486\n",
      "Training Loss:  [0.01394189]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  487\n",
      "Training Loss:  [0.01387516]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  488\n",
      "Training Loss:  [0.01385519]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  489\n",
      "Training Loss:  [0.01374287]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  490\n",
      "Training Loss:  [0.01371669]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  491\n",
      "Training Loss:  [0.01365607]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  492\n",
      "Training Loss:  [0.01360664]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  493\n",
      "Training Loss:  [0.01354965]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  494\n",
      "Training Loss:  [0.01348788]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  495\n",
      "Training Loss:  [0.01340106]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  496\n",
      "Training Loss:  [0.01339918]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  497\n",
      "Training Loss:  [0.01331773]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  498\n",
      "Training Loss:  [0.01326189]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  499\n",
      "Training Loss:  [0.01320656]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  500\n",
      "Training Loss:  [0.01316625]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  501\n",
      "Training Loss:  [0.01309123]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  502\n",
      "Training Loss:  [0.01306665]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  503\n",
      "Training Loss:  [0.01301254]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  504\n",
      "Training Loss:  [0.0129548]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  505\n",
      "Training Loss:  [0.01291593]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  506\n",
      "Training Loss:  [0.0128477]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  507\n",
      "Training Loss:  [0.01282727]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  508\n",
      "Training Loss:  [0.01278971]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  509\n",
      "Training Loss:  [0.01267604]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  510\n",
      "Training Loss:  [0.01265133]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  511\n",
      "Training Loss:  [0.01261034]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  512\n",
      "Training Loss:  [0.01255423]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  513\n",
      "Training Loss:  [0.01252114]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  514\n",
      "Training Loss:  [0.01248186]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  515\n",
      "Training Loss:  [0.0124397]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  516\n",
      "Training Loss:  [0.0124084]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  517\n",
      "Training Loss:  [0.01229259]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  518\n",
      "Training Loss:  [0.01228839]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  519\n",
      "Training Loss:  [0.01223756]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  520\n",
      "Training Loss:  [0.01217519]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  521\n",
      "Training Loss:  [0.01214816]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  522\n",
      "Training Loss:  [0.01210053]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  523\n",
      "Training Loss:  [0.01206969]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  524\n",
      "Training Loss:  [0.01199349]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  525\n",
      "Training Loss:  [0.01197351]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  526\n",
      "Training Loss:  [0.01195506]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  527\n",
      "Training Loss:  [0.01191866]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  528\n",
      "Training Loss:  [0.01182165]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  529\n",
      "Training Loss:  [0.01181429]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  530\n",
      "Training Loss:  [0.01176735]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  531\n",
      "Training Loss:  [0.01173701]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  532\n",
      "Training Loss:  [0.01163996]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  533\n",
      "Training Loss:  [0.01162219]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  534\n",
      "Training Loss:  [0.01159622]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  535\n",
      "Training Loss:  [0.01154307]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  536\n",
      "Training Loss:  [0.01152189]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  537\n",
      "Training Loss:  [0.01147516]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  538\n",
      "Training Loss:  [0.01145116]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  539\n",
      "Training Loss:  [0.01139626]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  540\n",
      "Training Loss:  [0.01137356]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  541\n",
      "Training Loss:  [0.01131414]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  542\n",
      "Training Loss:  [0.01127657]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  543\n",
      "Training Loss:  [0.01124486]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  544\n",
      "Training Loss:  [0.01120936]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  545\n",
      "Training Loss:  [0.01115376]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  546\n",
      "Training Loss:  [0.01112131]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  547\n",
      "Training Loss:  [0.01108654]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  548\n",
      "Training Loss:  [0.01103371]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  549\n",
      "Training Loss:  [0.01102636]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  550\n",
      "Training Loss:  [0.01100407]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  551\n",
      "Training Loss:  [0.01090833]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  552\n",
      "Training Loss:  [0.01088705]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  553\n",
      "Training Loss:  [0.01088658]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  554\n",
      "Training Loss:  [0.01081836]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  555\n",
      "Training Loss:  [0.01078881]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  556\n",
      "Training Loss:  [0.01075935]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  557\n",
      "Training Loss:  [0.01075718]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  558\n",
      "Training Loss:  [0.01067193]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  559\n",
      "Training Loss:  [0.01064486]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  560\n",
      "Training Loss:  [0.01062959]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  561\n",
      "Training Loss:  [0.01057904]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  562\n",
      "Training Loss:  [0.01054697]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  563\n",
      "Training Loss:  [0.01049891]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  564\n",
      "Training Loss:  [0.0104913]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  565\n",
      "Training Loss:  [0.01043318]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  566\n",
      "Training Loss:  [0.01041859]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  567\n",
      "Training Loss:  [0.01038292]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  568\n",
      "Training Loss:  [0.01037809]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  569\n",
      "Training Loss:  [0.0102975]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  570\n",
      "Training Loss:  [0.01026933]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  571\n",
      "Training Loss:  [0.0102418]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  572\n",
      "Training Loss:  [0.01021405]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  573\n",
      "Training Loss:  [0.01018811]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  574\n",
      "Training Loss:  [0.01014136]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  575\n",
      "Training Loss:  [0.01012236]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  576\n",
      "Training Loss:  [0.0100775]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  577\n",
      "Training Loss:  [0.01006448]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  578\n",
      "Training Loss:  [0.01003523]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  579\n",
      "Training Loss:  [0.01001488]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  580\n",
      "Training Loss:  [0.00996074]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  581\n",
      "Training Loss:  [0.00993069]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  582\n",
      "Training Loss:  [0.00990892]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  583\n",
      "Training Loss:  [0.00987307]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  584\n",
      "Training Loss:  [0.00985315]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  585\n",
      "Training Loss:  [0.00980734]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  586\n",
      "Training Loss:  [0.00978926]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  587\n",
      "Training Loss:  [0.00974633]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  588\n",
      "Training Loss:  [0.00973992]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  589\n",
      "Training Loss:  [0.00967942]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  590\n",
      "Training Loss:  [0.00966513]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  591\n",
      "Training Loss:  [0.00964329]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  592\n",
      "Training Loss:  [0.00960973]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  593\n",
      "Training Loss:  [0.00958077]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  594\n",
      "Training Loss:  [0.00953989]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  595\n",
      "Training Loss:  [0.00951497]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  596\n",
      "Training Loss:  [0.00949214]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  597\n",
      "Training Loss:  [0.00947431]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  598\n",
      "Training Loss:  [0.0094234]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  599\n",
      "Training Loss:  [0.00942722]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  600\n",
      "Training Loss:  [0.00939868]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  601\n",
      "Training Loss:  [0.00938344]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  602\n",
      "Training Loss:  [0.00931075]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  603\n",
      "Training Loss:  [0.00930296]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  604\n",
      "Training Loss:  [0.00929443]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  605\n",
      "Training Loss:  [0.00929728]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  606\n",
      "Training Loss:  [0.00921942]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  607\n",
      "Training Loss:  [0.00919368]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  608\n",
      "Training Loss:  [0.00917973]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  609\n",
      "Training Loss:  [0.00913627]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  610\n",
      "Training Loss:  [0.00911726]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  611\n",
      "Training Loss:  [0.00908015]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  612\n",
      "Training Loss:  [0.00907029]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  613\n",
      "Training Loss:  [0.00903388]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  614\n",
      "Training Loss:  [0.00900771]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  615\n",
      "Training Loss:  [0.00899573]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  616\n",
      "Training Loss:  [0.00895812]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  617\n",
      "Training Loss:  [0.00895063]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  618\n",
      "Training Loss:  [0.00890477]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  619\n",
      "Training Loss:  [0.00890509]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  620\n",
      "Training Loss:  [0.00887391]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  621\n",
      "Training Loss:  [0.00885673]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  622\n",
      "Training Loss:  [0.00879808]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  623\n",
      "Training Loss:  [0.00879858]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  624\n",
      "Training Loss:  [0.00877202]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  625\n",
      "Training Loss:  [0.00874134]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  626\n",
      "Training Loss:  [0.0087226]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  627\n",
      "Training Loss:  [0.00870031]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  628\n",
      "Training Loss:  [0.00868157]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  629\n",
      "Training Loss:  [0.00864265]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  630\n",
      "Training Loss:  [0.00863487]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  631\n",
      "Training Loss:  [0.00860544]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  632\n",
      "Training Loss:  [0.0085834]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  633\n",
      "Training Loss:  [0.00856863]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  634\n",
      "Training Loss:  [0.00852843]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  635\n",
      "Training Loss:  [0.00852683]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  636\n",
      "Training Loss:  [0.00849251]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  637\n",
      "Training Loss:  [0.00847373]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  638\n",
      "Training Loss:  [0.00843383]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  639\n",
      "Training Loss:  [0.00844129]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  640\n",
      "Training Loss:  [0.00839574]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  641\n",
      "Training Loss:  [0.00838811]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  642\n",
      "Training Loss:  [0.00835634]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  643\n",
      "Training Loss:  [0.00835441]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  644\n",
      "Training Loss:  [0.00830179]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  645\n",
      "Training Loss:  [0.00829385]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  646\n",
      "Training Loss:  [0.00826665]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  647\n",
      "Training Loss:  [0.00825808]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  648\n",
      "Training Loss:  [0.00823908]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  649\n",
      "Training Loss:  [0.00820634]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  650\n",
      "Training Loss:  [0.00820146]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  651\n",
      "Training Loss:  [0.00817312]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  652\n",
      "Training Loss:  [0.00815802]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  653\n",
      "Training Loss:  [0.00813206]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  654\n",
      "Training Loss:  [0.00811782]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  655\n",
      "Training Loss:  [0.00807806]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  656\n",
      "Training Loss:  [0.00806935]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  657\n",
      "Training Loss:  [0.00804653]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  658\n",
      "Training Loss:  [0.008038]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  659\n",
      "Training Loss:  [0.00799711]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  660\n",
      "Training Loss:  [0.0079879]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  661\n",
      "Training Loss:  [0.00796676]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  662\n",
      "Training Loss:  [0.0079412]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  663\n",
      "Training Loss:  [0.00793795]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  664\n",
      "Training Loss:  [0.00790537]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  665\n",
      "Training Loss:  [0.0078948]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  666\n",
      "Training Loss:  [0.00787346]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  667\n",
      "Training Loss:  [0.00785959]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  668\n",
      "Training Loss:  [0.00785362]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  669\n",
      "Training Loss:  [0.00783997]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  670\n",
      "Training Loss:  [0.00779103]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  671\n",
      "Training Loss:  [0.00778359]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  672\n",
      "Training Loss:  [0.00776109]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  673\n",
      "Training Loss:  [0.00775261]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  674\n",
      "Training Loss:  [0.00770054]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  675\n",
      "Training Loss:  [0.00769623]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  676\n",
      "Training Loss:  [0.00768659]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  677\n",
      "Training Loss:  [0.007664]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  678\n",
      "Training Loss:  [0.00764962]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  679\n",
      "Training Loss:  [0.00763073]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  680\n",
      "Training Loss:  [0.00762179]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  681\n",
      "Training Loss:  [0.00760026]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  682\n",
      "Training Loss:  [0.00757874]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  683\n",
      "Training Loss:  [0.00757333]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  684\n",
      "Training Loss:  [0.00757265]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  685\n",
      "Training Loss:  [0.007527]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  686\n",
      "Training Loss:  [0.0075086]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  687\n",
      "Training Loss:  [0.00749556]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  688\n",
      "Training Loss:  [0.00748626]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  689\n",
      "Training Loss:  [0.00743959]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  690\n",
      "Training Loss:  [0.00743482]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  691\n",
      "Training Loss:  [0.00741273]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  692\n",
      "Training Loss:  [0.00741763]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  693\n",
      "Training Loss:  [0.00736808]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  694\n",
      "Training Loss:  [0.00736372]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  695\n",
      "Training Loss:  [0.00735181]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  696\n",
      "Training Loss:  [0.00733346]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  697\n",
      "Training Loss:  [0.00733273]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  698\n",
      "Training Loss:  [0.007293]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  699\n",
      "Training Loss:  [0.00728795]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  700\n",
      "Training Loss:  [0.00726479]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  701\n",
      "Training Loss:  [0.00726063]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  702\n",
      "Training Loss:  [0.00723522]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  703\n",
      "Training Loss:  [0.00721724]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  704\n",
      "Training Loss:  [0.00721957]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  705\n",
      "Training Loss:  [0.00718995]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  706\n",
      "Training Loss:  [0.00718101]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  707\n",
      "Training Loss:  [0.00717265]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  708\n",
      "Training Loss:  [0.00713662]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  709\n",
      "Training Loss:  [0.00712739]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  710\n",
      "Training Loss:  [0.00709979]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  711\n",
      "Training Loss:  [0.00708549]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  712\n",
      "Training Loss:  [0.00708481]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  713\n",
      "Training Loss:  [0.00705829]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  714\n",
      "Training Loss:  [0.00704816]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  715\n",
      "Training Loss:  [0.00702585]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  716\n",
      "Training Loss:  [0.00702262]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  717\n",
      "Training Loss:  [0.00699835]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  718\n",
      "Training Loss:  [0.0069881]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  719\n",
      "Training Loss:  [0.00696551]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  720\n",
      "Training Loss:  [0.00695768]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  721\n",
      "Training Loss:  [0.00694197]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  722\n",
      "Training Loss:  [0.00693436]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  723\n",
      "Training Loss:  [0.0069169]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  724\n",
      "Training Loss:  [0.00689988]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  725\n",
      "Training Loss:  [0.00690237]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  726\n",
      "Training Loss:  [0.00689175]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  727\n",
      "Training Loss:  [0.00685267]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  728\n",
      "Training Loss:  [0.00683891]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  729\n",
      "Training Loss:  [0.00681949]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  730\n",
      "Training Loss:  [0.00681644]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  731\n",
      "Training Loss:  [0.00678603]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  732\n",
      "Training Loss:  [0.00678313]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  733\n",
      "Training Loss:  [0.00677109]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  734\n",
      "Training Loss:  [0.00677198]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  735\n",
      "Training Loss:  [0.00673229]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  736\n",
      "Training Loss:  [0.00672602]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  737\n",
      "Training Loss:  [0.00671926]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  738\n",
      "Training Loss:  [0.00671227]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  739\n",
      "Training Loss:  [0.00667271]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  740\n",
      "Training Loss:  [0.00667028]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  741\n",
      "Training Loss:  [0.00665203]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  742\n",
      "Training Loss:  [0.00664288]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  743\n",
      "Training Loss:  [0.00663912]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  744\n",
      "Training Loss:  [0.00661366]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  745\n",
      "Training Loss:  [0.00660598]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  746\n",
      "Training Loss:  [0.00661051]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  747\n",
      "Training Loss:  [0.00657019]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  748\n",
      "Training Loss:  [0.00656254]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  749\n",
      "Training Loss:  [0.00655062]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  750\n",
      "Training Loss:  [0.00654498]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  751\n",
      "Training Loss:  [0.00651556]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  752\n",
      "Training Loss:  [0.00651343]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  753\n",
      "Training Loss:  [0.00649565]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  754\n",
      "Training Loss:  [0.00648203]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  755\n",
      "Training Loss:  [0.00648337]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  756\n",
      "Training Loss:  [0.00645967]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  757\n",
      "Training Loss:  [0.00645166]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  758\n",
      "Training Loss:  [0.00644635]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  759\n",
      "Training Loss:  [0.00641439]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  760\n",
      "Training Loss:  [0.00640949]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  761\n",
      "Training Loss:  [0.00639575]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  762\n",
      "Training Loss:  [0.00639049]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  763\n",
      "Training Loss:  [0.0063622]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  764\n",
      "Training Loss:  [0.00636055]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  765\n",
      "Training Loss:  [0.00634121]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  766\n",
      "Training Loss:  [0.00632936]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  767\n",
      "Training Loss:  [0.00632266]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  768\n",
      "Training Loss:  [0.00631177]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  769\n",
      "Training Loss:  [0.00630198]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  770\n",
      "Training Loss:  [0.00629675]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  771\n",
      "Training Loss:  [0.00626661]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  772\n",
      "Training Loss:  [0.00626484]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  773\n",
      "Training Loss:  [0.00624858]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  774\n",
      "Training Loss:  [0.006235]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  775\n",
      "Training Loss:  [0.00623047]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  776\n",
      "Training Loss:  [0.00622352]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  777\n",
      "Training Loss:  [0.00619983]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  778\n",
      "Training Loss:  [0.00619292]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  779\n",
      "Training Loss:  [0.00618019]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  780\n",
      "Training Loss:  [0.00617705]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  781\n",
      "Training Loss:  [0.00615157]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  782\n",
      "Training Loss:  [0.00615053]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  783\n",
      "Training Loss:  [0.00612448]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  784\n",
      "Training Loss:  [0.00612324]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  785\n",
      "Training Loss:  [0.00611801]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  786\n",
      "Training Loss:  [0.00611021]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  787\n",
      "Training Loss:  [0.0060784]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  788\n",
      "Training Loss:  [0.00607724]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  789\n",
      "Training Loss:  [0.0060673]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  790\n",
      "Training Loss:  [0.00605601]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  791\n",
      "Training Loss:  [0.00605076]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  792\n",
      "Training Loss:  [0.00605085]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  793\n",
      "Training Loss:  [0.00602277]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  794\n",
      "Training Loss:  [0.00603144]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  795\n",
      "Training Loss:  [0.00602707]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  796\n",
      "Training Loss:  [0.00598946]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  797\n",
      "Training Loss:  [0.0059792]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  798\n",
      "Training Loss:  [0.00596829]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  799\n",
      "Training Loss:  [0.00596417]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  800\n",
      "Training Loss:  [0.00593336]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  801\n",
      "Training Loss:  [0.00593261]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  802\n",
      "Training Loss:  [0.0059261]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  803\n",
      "Training Loss:  [0.00592715]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  804\n",
      "Training Loss:  [0.00589469]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  805\n",
      "Training Loss:  [0.00589326]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  806\n",
      "Training Loss:  [0.00588441]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  807\n",
      "Training Loss:  [0.00587398]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  808\n",
      "Training Loss:  [0.00586895]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  809\n",
      "Training Loss:  [0.00586934]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  810\n",
      "Training Loss:  [0.00584108]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  811\n",
      "Training Loss:  [0.00582994]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  812\n",
      "Training Loss:  [0.00585971]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  813\n",
      "Training Loss:  [0.00582241]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  814\n",
      "Training Loss:  [0.0057988]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  815\n",
      "Training Loss:  [0.00580173]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  816\n",
      "Training Loss:  [0.00579717]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  817\n",
      "Training Loss:  [0.00576384]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  818\n",
      "Training Loss:  [0.00575868]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  819\n",
      "Training Loss:  [0.00574905]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  820\n",
      "Training Loss:  [0.00574095]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  821\n",
      "Training Loss:  [0.00573931]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  822\n",
      "Training Loss:  [0.00573986]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  823\n",
      "Training Loss:  [0.00571237]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  824\n",
      "Training Loss:  [0.00571533]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  825\n",
      "Training Loss:  [0.00571787]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  826\n",
      "Training Loss:  [0.00568323]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  827\n",
      "Training Loss:  [0.00567649]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  828\n",
      "Training Loss:  [0.00565073]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  829\n",
      "Training Loss:  [0.00565518]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  830\n",
      "Training Loss:  [0.00563855]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  831\n",
      "Training Loss:  [0.00564065]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  832\n",
      "Training Loss:  [0.00561711]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  833\n",
      "Training Loss:  [0.00561921]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  834\n",
      "Training Loss:  [0.0056077]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  835\n",
      "Training Loss:  [0.00560555]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  836\n",
      "Training Loss:  [0.00558239]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  837\n",
      "Training Loss:  [0.00558061]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  838\n",
      "Training Loss:  [0.00558468]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  839\n",
      "Training Loss:  [0.00555198]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  840\n",
      "Training Loss:  [0.00554772]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  841\n",
      "Training Loss:  [0.00553819]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  842\n",
      "Training Loss:  [0.00553209]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  843\n",
      "Training Loss:  [0.00552914]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  844\n",
      "Training Loss:  [0.00553001]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  845\n",
      "Training Loss:  [0.00550383]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  846\n",
      "Training Loss:  [0.00550536]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  847\n",
      "Training Loss:  [0.00550709]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  848\n",
      "Training Loss:  [0.00547476]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  849\n",
      "Training Loss:  [0.00546775]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  850\n",
      "Training Loss:  [0.00544795]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  851\n",
      "Training Loss:  [0.00545055]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  852\n",
      "Training Loss:  [0.00543506]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  853\n",
      "Training Loss:  [0.00542394]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  854\n",
      "Training Loss:  [0.00541668]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  855\n",
      "Training Loss:  [0.0054118]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  856\n",
      "Training Loss:  [0.00541537]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  857\n",
      "Training Loss:  [0.00538673]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  858\n",
      "Training Loss:  [0.00538703]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  859\n",
      "Training Loss:  [0.00538012]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  860\n",
      "Training Loss:  [0.0053801]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  861\n",
      "Training Loss:  [0.00535552]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  862\n",
      "Training Loss:  [0.00535588]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  863\n",
      "Training Loss:  [0.00534854]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  864\n",
      "Training Loss:  [0.00534102]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  865\n",
      "Training Loss:  [0.00534556]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  866\n",
      "Training Loss:  [0.00531337]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  867\n",
      "Training Loss:  [0.00530993]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  868\n",
      "Training Loss:  [0.0053006]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  869\n",
      "Training Loss:  [0.00529204]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  870\n",
      "Training Loss:  [0.00529197]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  871\n",
      "Training Loss:  [0.00528419]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  872\n",
      "Training Loss:  [0.00526536]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  873\n",
      "Training Loss:  [0.00526137]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  874\n",
      "Training Loss:  [0.00524773]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  875\n",
      "Training Loss:  [0.00524568]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  876\n",
      "Training Loss:  [0.00523992]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  877\n",
      "Training Loss:  [0.00522118]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  878\n",
      "Training Loss:  [0.0052263]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  879\n",
      "Training Loss:  [0.00521591]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  880\n",
      "Training Loss:  [0.00520779]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  881\n",
      "Training Loss:  [0.00519216]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  882\n",
      "Training Loss:  [0.00518601]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  883\n",
      "Training Loss:  [0.00517496]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  884\n",
      "Training Loss:  [0.00517906]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  885\n",
      "Training Loss:  [0.00517272]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  886\n",
      "Training Loss:  [0.00515291]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  887\n",
      "Training Loss:  [0.00515147]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  888\n",
      "Training Loss:  [0.00516437]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  889\n",
      "Training Loss:  [0.00513186]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  890\n",
      "Training Loss:  [0.00512544]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  891\n",
      "Training Loss:  [0.00511981]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  892\n",
      "Training Loss:  [0.00510744]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  893\n",
      "Training Loss:  [0.00511106]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  894\n",
      "Training Loss:  [0.0051039]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  895\n",
      "Training Loss:  [0.00508515]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  896\n",
      "Training Loss:  [0.00508266]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  897\n",
      "Training Loss:  [0.00508433]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  898\n",
      "Training Loss:  [0.00505783]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  899\n",
      "Training Loss:  [0.00505853]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  900\n",
      "Training Loss:  [0.00505277]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  901\n",
      "Training Loss:  [0.00504129]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  902\n",
      "Training Loss:  [0.00506896]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  903\n",
      "Training Loss:  [0.005038]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  904\n",
      "Training Loss:  [0.00503204]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  905\n",
      "Training Loss:  [0.00500986]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  906\n",
      "Training Loss:  [0.00500627]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  907\n",
      "Training Loss:  [0.00502305]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  908\n",
      "Training Loss:  [0.004992]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  909\n",
      "Training Loss:  [0.00498703]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  910\n",
      "Training Loss:  [0.00496814]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  911\n",
      "Training Loss:  [0.00496907]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  912\n",
      "Training Loss:  [0.0049656]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  913\n",
      "Training Loss:  [0.00495827]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  914\n",
      "Training Loss:  [0.00494517]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  915\n",
      "Training Loss:  [0.00493767]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  916\n",
      "Training Loss:  [0.00493461]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  917\n",
      "Training Loss:  [0.00493012]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  918\n",
      "Training Loss:  [0.00492333]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  919\n",
      "Training Loss:  [0.00490812]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  920\n",
      "Training Loss:  [0.00490293]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  921\n",
      "Training Loss:  [0.00489735]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  922\n",
      "Training Loss:  [0.00489498]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  923\n",
      "Training Loss:  [0.00488853]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  924\n",
      "Training Loss:  [0.00487244]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  925\n",
      "Training Loss:  [0.00486941]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  926\n",
      "Training Loss:  [0.00486305]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  927\n",
      "Training Loss:  [0.00486137]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  928\n",
      "Training Loss:  [0.00485529]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  929\n",
      "Training Loss:  [0.0048388]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  930\n",
      "Training Loss:  [0.00483564]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  931\n",
      "Training Loss:  [0.00482804]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  932\n",
      "Training Loss:  [0.0048265]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  933\n",
      "Training Loss:  [0.00482059]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  934\n",
      "Training Loss:  [0.0048082]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  935\n",
      "Training Loss:  [0.00480462]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  936\n",
      "Training Loss:  [0.00479394]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  937\n",
      "Training Loss:  [0.00479196]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  938\n",
      "Training Loss:  [0.00478609]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  939\n",
      "Training Loss:  [0.00477033]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  940\n",
      "Training Loss:  [0.00477162]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  941\n",
      "Training Loss:  [0.00476195]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  942\n",
      "Training Loss:  [0.00475923]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  943\n",
      "Training Loss:  [0.00475328]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  944\n",
      "Training Loss:  [0.00473917]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  945\n",
      "Training Loss:  [0.00473753]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  946\n",
      "Training Loss:  [0.00472922]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  947\n",
      "Training Loss:  [0.00472557]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  948\n",
      "Training Loss:  [0.00471948]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  949\n",
      "Training Loss:  [0.00470595]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  950\n",
      "Training Loss:  [0.0047053]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  951\n",
      "Training Loss:  [0.00469846]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  952\n",
      "Training Loss:  [0.00469372]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  953\n",
      "Training Loss:  [0.00468752]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  954\n",
      "Training Loss:  [0.00467899]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  955\n",
      "Training Loss:  [0.00467275]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  956\n",
      "Training Loss:  [0.00466688]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  957\n",
      "Training Loss:  [0.004661]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  958\n",
      "Training Loss:  [0.00465491]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  959\n",
      "Training Loss:  [0.00464767]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  960\n",
      "Training Loss:  [0.00464093]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  961\n",
      "Training Loss:  [0.00463587]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  962\n",
      "Training Loss:  [0.00462876]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  963\n",
      "Training Loss:  [0.00463132]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  964\n",
      "Training Loss:  [0.0046198]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  965\n",
      "Training Loss:  [0.00461652]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  966\n",
      "Training Loss:  [0.00460645]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  967\n",
      "Training Loss:  [0.00462717]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  968\n",
      "Training Loss:  [0.00459821]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  969\n",
      "Training Loss:  [0.00459697]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  970\n",
      "Training Loss:  [0.00457984]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  971\n",
      "Training Loss:  [0.00457643]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  972\n",
      "Training Loss:  [0.00456786]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  973\n",
      "Training Loss:  [0.00456157]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  974\n",
      "Training Loss:  [0.00456021]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  975\n",
      "Training Loss:  [0.00455301]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  976\n",
      "Training Loss:  [0.004553]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  977\n",
      "Training Loss:  [0.00453794]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  978\n",
      "Training Loss:  [0.00453477]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  979\n",
      "Training Loss:  [0.00453323]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  980\n",
      "Training Loss:  [0.00452187]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  981\n",
      "Training Loss:  [0.00451594]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  982\n",
      "Training Loss:  [0.00451454]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  983\n",
      "Training Loss:  [0.00450768]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  984\n",
      "Training Loss:  [0.00450996]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  985\n",
      "Training Loss:  [0.00450538]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  986\n",
      "Training Loss:  [0.00448341]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  987\n",
      "Training Loss:  [0.00448445]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  988\n",
      "Training Loss:  [0.00449591]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  989\n",
      "Training Loss:  [0.00446951]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  990\n",
      "Training Loss:  [0.00446698]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  991\n",
      "Training Loss:  [0.00446084]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  992\n",
      "Training Loss:  [0.00446114]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  993\n",
      "Training Loss:  [0.00445089]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  994\n",
      "Training Loss:  [0.00444741]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  995\n",
      "Training Loss:  [0.00444178]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  996\n",
      "Training Loss:  [0.00443841]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  997\n",
      "Training Loss:  [0.00442117]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  998\n",
      "Training Loss:  [0.00442597]\n",
      "Training Accuracy:  1.0\n",
      "\n",
      "Epoch  999\n",
      "Training Loss:  [0.00441694]\n",
      "Training Accuracy:  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(X_train, y_train, epochs=1000, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 0, 0] [0]\n",
      "Training Loss:  [0.00441694]\n",
      "Training Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train), model.predict(np.array([[1,1,0]])))\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
